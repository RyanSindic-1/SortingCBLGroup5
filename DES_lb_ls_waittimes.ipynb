{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93ac88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:00:22.837000] Parcel 1 removed from outfeed 0\n",
      "[09:00:29.875000] Parcel 16 removed from outfeed 2\n",
      "[09:00:32.837000] Parcel 2 removed from outfeed 0\n",
      "[09:00:39.875000] Parcel 149 removed from outfeed 2\n",
      "[09:00:40.837000] Parcel 3 removed from outfeed 0\n",
      "[09:00:49.837000] Parcel 4 removed from outfeed 0\n",
      "[09:00:49.875000] Parcel 133 removed from outfeed 2\n",
      "[09:00:57.227000] Parcel 9 removed from outfeed 1\n",
      "[09:00:58.875000] Parcel 6 removed from outfeed 2\n",
      "[09:00:59.837000] Parcel 5 removed from outfeed 0\n",
      "[09:01:06.227000] Parcel 10 removed from outfeed 1\n",
      "[09:01:07.875000] Parcel 11 removed from outfeed 2\n",
      "[09:01:10.837000] Parcel 7 removed from outfeed 0\n",
      "[09:01:15.875000] Parcel 12 removed from outfeed 2\n",
      "[09:01:22.837000] Parcel 8 removed from outfeed 0\n",
      "[09:01:26.875000] Parcel 15 removed from outfeed 2\n",
      "[09:01:33.837000] Parcel 14 removed from outfeed 0\n",
      "[09:01:36.875000] Parcel 17 removed from outfeed 2\n",
      "[09:01:44.875000] Parcel 18 removed from outfeed 2\n",
      "[09:01:50.039000] Parcel 25 removed from outfeed 0\n",
      "[09:01:56.875000] Parcel 19 removed from outfeed 2\n",
      "[09:01:59.039000] Parcel 27 removed from outfeed 0\n",
      "[09:01:59.105000] Parcel 29 removed from outfeed 1\n",
      "[09:02:05.875000] Parcel 20 removed from outfeed 2\n",
      "[09:02:11.039000] Parcel 28 removed from outfeed 0\n",
      "[09:02:16.127000] Parcel 33 removed from outfeed 1\n",
      "[09:02:17.875000] Parcel 21 removed from outfeed 2\n",
      "[09:02:21.039000] Parcel 31 removed from outfeed 0\n",
      "[09:02:27.068000] Parcel 38 removed from outfeed 1\n",
      "[09:02:28.875000] Parcel 22 removed from outfeed 2\n",
      "[09:02:32.039000] Parcel 32 removed from outfeed 0\n",
      "[09:02:37.875000] Parcel 23 removed from outfeed 2\n",
      "[09:02:40.039000] Parcel 35 removed from outfeed 0\n",
      "[09:02:49.875000] Parcel 34 removed from outfeed 2\n",
      "[09:02:51.039000] Parcel 42 removed from outfeed 0\n",
      "[09:02:58.875000] Parcel 36 removed from outfeed 2\n",
      "[09:03:00.039000] Parcel 43 removed from outfeed 0\n",
      "[09:03:05.192000] Parcel 51 removed from outfeed 1\n",
      "[09:03:10.039000] Parcel 46 removed from outfeed 0\n",
      "[09:03:10.875000] Parcel 24 removed from outfeed 2\n",
      "[09:03:13.882000] Parcel 55 removed from outfeed 1\n",
      "[09:03:18.875000] Parcel 41 removed from outfeed 2\n",
      "[09:03:20.039000] Parcel 52 removed from outfeed 0\n",
      "[09:03:24.882000] Parcel 56 removed from outfeed 1\n",
      "[09:03:28.039000] Parcel 53 removed from outfeed 0\n",
      "[09:03:30.875000] Parcel 39 removed from outfeed 2\n",
      "[09:03:37.039000] Parcel 47 removed from outfeed 0\n",
      "[09:03:41.875000] Parcel 40 removed from outfeed 2\n",
      "[09:03:45.490000] Parcel 62 removed from outfeed 1\n",
      "[09:03:49.039000] Parcel 58 removed from outfeed 0\n",
      "[09:03:53.875000] Parcel 54 removed from outfeed 2\n",
      "[09:03:55.490000] Parcel 64 removed from outfeed 1\n",
      "[09:04:03.875000] Parcel 60 removed from outfeed 2\n",
      "[09:04:04.836000] Parcel 67 removed from outfeed 0\n",
      "[09:04:13.875000] Parcel 61 removed from outfeed 2\n",
      "[09:04:24.875000] Parcel 49 removed from outfeed 2\n",
      "[09:04:36.396000] Parcel 74 removed from outfeed 1\n",
      "[09:04:36.875000] Parcel 37 removed from outfeed 2\n",
      "[09:04:45.008000] Parcel 78 removed from outfeed 0\n",
      "[09:04:45.875000] Parcel 50 removed from outfeed 2\n",
      "[09:04:48.396000] Parcel 77 removed from outfeed 1\n",
      "[09:04:55.008000] Parcel 79 removed from outfeed 0\n",
      "[09:04:57.875000] Parcel 63 removed from outfeed 2\n",
      "[09:05:03.008000] Parcel 80 removed from outfeed 0\n",
      "[09:05:06.875000] Parcel 68 removed from outfeed 2\n",
      "[09:05:07.530000] Parcel 83 removed from outfeed 1\n",
      "[09:05:14.008000] Parcel 81 removed from outfeed 0\n",
      "[09:05:17.875000] Parcel 48 removed from outfeed 2\n",
      "[09:05:22.008000] Parcel 84 removed from outfeed 0\n",
      "[09:05:29.875000] Parcel 59 removed from outfeed 2\n",
      "[09:05:33.008000] Parcel 85 removed from outfeed 0\n",
      "[09:05:39.875000] Parcel 69 removed from outfeed 2\n",
      "[09:05:40.110000] Parcel 91 removed from outfeed 1\n",
      "[09:05:43.008000] Parcel 86 removed from outfeed 0\n",
      "[09:05:50.110000] Parcel 92 removed from outfeed 1\n",
      "[09:05:51.875000] Parcel 70 removed from outfeed 2\n",
      "[09:05:54.008000] Parcel 90 removed from outfeed 0\n",
      "[09:05:59.110000] Parcel 96 removed from outfeed 1\n",
      "[09:05:59.875000] Parcel 71 removed from outfeed 2\n",
      "[09:06:05.008000] Parcel 93 removed from outfeed 0\n",
      "[09:06:09.875000] Parcel 72 removed from outfeed 2\n",
      "[09:06:11.110000] Parcel 97 removed from outfeed 1\n",
      "[09:06:15.008000] Parcel 94 removed from outfeed 0\n",
      "[09:06:19.875000] Parcel 95 removed from outfeed 2\n",
      "[09:06:24.056000] Parcel 107 removed from outfeed 1\n",
      "[09:06:25.008000] Parcel 99 removed from outfeed 0\n",
      "[09:06:30.875000] Parcel 98 removed from outfeed 2\n",
      "[09:06:35.622000] Parcel 108 removed from outfeed 1\n",
      "[09:06:36.008000] Parcel 101 removed from outfeed 0\n",
      "[09:06:42.875000] Parcel 87 removed from outfeed 2\n",
      "[09:06:48.008000] Parcel 102 removed from outfeed 0\n",
      "[09:06:52.875000] Parcel 88 removed from outfeed 2\n",
      "[09:06:57.008000] Parcel 113 removed from outfeed 0\n",
      "[09:07:03.875000] Parcel 76 removed from outfeed 2\n",
      "[09:07:08.008000] Parcel 115 removed from outfeed 0\n",
      "[09:07:13.875000] Parcel 57 removed from outfeed 2\n",
      "[09:07:20.008000] Parcel 104 removed from outfeed 0\n",
      "[09:07:22.875000] Parcel 109 removed from outfeed 2\n",
      "[09:07:29.008000] Parcel 117 removed from outfeed 0\n",
      "[09:07:33.875000] Parcel 110 removed from outfeed 2\n",
      "[09:07:39.008000] Parcel 106 removed from outfeed 0\n",
      "[09:07:41.875000] Parcel 111 removed from outfeed 2\n",
      "[09:07:49.008000] Parcel 120 removed from outfeed 0\n",
      "[09:07:52.875000] Parcel 100 removed from outfeed 2\n",
      "[09:07:59.008000] Parcel 131 removed from outfeed 0\n",
      "[09:08:03.875000] Parcel 114 removed from outfeed 2\n",
      "[09:08:10.008000] Parcel 132 removed from outfeed 0\n",
      "[09:08:10.981000] Parcel 136 removed from outfeed 1\n",
      "[09:08:12.875000] Parcel 124 removed from outfeed 2\n",
      "[09:08:20.981000] Parcel 137 removed from outfeed 1\n",
      "[09:08:21.008000] Parcel 123 removed from outfeed 0\n",
      "[09:08:23.875000] Parcel 73 removed from outfeed 2\n",
      "[09:08:28.981000] Parcel 141 removed from outfeed 1\n",
      "[09:08:30.008000] Parcel 134 removed from outfeed 0\n",
      "[09:08:33.875000] Parcel 89 removed from outfeed 2\n",
      "[09:08:39.008000] Parcel 139 removed from outfeed 0\n",
      "[09:08:42.875000] Parcel 125 removed from outfeed 2\n",
      "[09:08:49.008000] Parcel 140 removed from outfeed 0\n",
      "[09:08:53.875000] Parcel 116 removed from outfeed 2\n",
      "[09:08:59.008000] Parcel 142 removed from outfeed 0\n",
      "[09:09:03.875000] Parcel 82 removed from outfeed 2\n",
      "[09:09:09.008000] Parcel 146 removed from outfeed 0\n",
      "[09:09:11.875000] Parcel 145 removed from outfeed 2\n",
      "[09:09:16.623000] Parcel 156 removed from outfeed 1\n",
      "[09:09:20.008000] Parcel 126 removed from outfeed 0\n",
      "[09:09:22.875000] Parcel 65 removed from outfeed 2\n",
      "[09:09:31.008000] Parcel 147 removed from outfeed 0\n",
      "[09:09:32.875000] Parcel 105 removed from outfeed 2\n",
      "[09:09:43.008000] Parcel 127 removed from outfeed 0\n",
      "[09:09:44.875000] Parcel 148 removed from outfeed 2\n",
      "[09:09:51.310000] Parcel 162 removed from outfeed 1\n",
      "[09:09:54.008000] Parcel 159 removed from outfeed 0\n",
      "[09:09:54.875000] Parcel 66 removed from outfeed 2\n",
      "[09:10:03.008000] Parcel 150 removed from outfeed 0\n",
      "[09:10:06.875000] Parcel 128 removed from outfeed 2\n",
      "[09:10:12.008000] Parcel 152 removed from outfeed 0\n",
      "[09:10:18.875000] Parcel 44 removed from outfeed 2\n",
      "[09:10:23.049000] Parcel 170 removed from outfeed 1\n",
      "[09:10:24.008000] Parcel 155 removed from outfeed 0\n",
      "[09:10:28.875000] Parcel 118 removed from outfeed 2\n",
      "[09:10:31.049000] Parcel 174 removed from outfeed 1\n",
      "[09:10:33.008000] Parcel 157 removed from outfeed 0\n",
      "[09:10:37.875000] Parcel 138 removed from outfeed 2\n",
      "[09:10:43.008000] Parcel 158 removed from outfeed 0\n",
      "[09:10:43.049000] Parcel 176 removed from outfeed 1\n",
      "[09:10:47.875000] Parcel 130 removed from outfeed 2\n",
      "[09:10:54.008000] Parcel 169 removed from outfeed 0\n",
      "[09:10:55.049000] Parcel 179 removed from outfeed 1\n",
      "[09:10:55.875000] Parcel 119 removed from outfeed 2\n",
      "[09:11:04.049000] Parcel 182 removed from outfeed 1\n",
      "[09:11:05.008000] Parcel 171 removed from outfeed 0\n",
      "[09:11:05.875000] Parcel 153 removed from outfeed 2\n",
      "[09:11:15.049000] Parcel 183 removed from outfeed 1\n",
      "[09:11:15.875000] Parcel 154 removed from outfeed 2\n",
      "[09:11:16.008000] Parcel 165 removed from outfeed 0\n",
      "[09:11:24.049000] Parcel 184 removed from outfeed 1\n",
      "[09:11:25.008000] Parcel 166 removed from outfeed 0\n",
      "[09:11:27.875000] Parcel 168 removed from outfeed 2\n",
      "[09:11:32.049000] Parcel 185 removed from outfeed 1\n",
      "[09:11:35.008000] Parcel 172 removed from outfeed 0\n",
      "[09:11:35.875000] Parcel 112 removed from outfeed 2\n",
      "[09:11:41.049000] Parcel 189 removed from outfeed 1\n",
      "[09:11:46.008000] Parcel 188 removed from outfeed 0\n",
      "[09:11:46.875000] Parcel 121 removed from outfeed 2\n",
      "[09:11:52.049000] Parcel 192 removed from outfeed 1\n",
      "[09:11:55.008000] Parcel 151 removed from outfeed 0\n",
      "[09:11:57.875000] Parcel 161 removed from outfeed 2\n",
      "[09:12:02.049000] Parcel 197 removed from outfeed 1\n",
      "[09:12:03.008000] Parcel 180 removed from outfeed 0\n",
      "[09:12:06.875000] Parcel 143 removed from outfeed 2\n",
      "[09:12:13.008000] Parcel 198 removed from outfeed 0\n",
      "[09:12:13.049000] Parcel 200 removed from outfeed 1\n",
      "[09:12:15.875000] Parcel 201 removed from outfeed 2\n",
      "[09:12:23.049000] Parcel 208 removed from outfeed 1\n",
      "[09:12:24.008000] Parcel 163 removed from outfeed 0\n",
      "[09:12:24.875000] Parcel 202 removed from outfeed 2\n",
      "[09:12:33.008000] Parcel 175 removed from outfeed 0\n",
      "[09:12:34.875000] Parcel 187 removed from outfeed 2\n",
      "[09:12:35.049000] Parcel 211 removed from outfeed 1\n",
      "[09:12:44.875000] Parcel 177 removed from outfeed 2\n",
      "[09:12:45.008000] Parcel 199 removed from outfeed 0\n",
      "[09:12:47.765000] Parcel 219 removed from outfeed 1\n",
      "[09:12:54.008000] Parcel 213 removed from outfeed 0\n",
      "[09:12:54.875000] Parcel 205 removed from outfeed 2\n",
      "[09:13:04.875000] Parcel 45 removed from outfeed 2\n",
      "[09:13:06.008000] Parcel 214 removed from outfeed 0\n",
      "[09:13:07.472000] Parcel 227 removed from outfeed 1\n",
      "[09:13:14.875000] Parcel 129 removed from outfeed 2\n",
      "[09:13:15.008000] Parcel 209 removed from outfeed 0\n",
      "[09:13:15.472000] Parcel 228 removed from outfeed 1\n",
      "[09:13:23.008000] Parcel 167 removed from outfeed 0\n",
      "[09:13:26.875000] Parcel 178 removed from outfeed 2\n",
      "[09:13:34.008000] Parcel 160 removed from outfeed 0\n",
      "[09:13:36.875000] Parcel 218 removed from outfeed 2\n",
      "[09:13:44.008000] Parcel 191 removed from outfeed 0\n",
      "[09:13:46.875000] Parcel 229 removed from outfeed 2\n",
      "[09:13:55.008000] Parcel 194 removed from outfeed 0\n",
      "[09:13:56.875000] Parcel 190 removed from outfeed 2\n",
      "[09:14:03.345000] Parcel 238 removed from outfeed 1\n",
      "[09:14:04.008000] Parcel 233 removed from outfeed 0\n",
      "[09:14:04.875000] Parcel 230 removed from outfeed 2\n",
      "[09:14:14.008000] Parcel 221 removed from outfeed 0\n",
      "[09:14:16.676000] Parcel 240 removed from outfeed 1\n",
      "[09:14:16.875000] Parcel 231 removed from outfeed 2\n",
      "[09:14:23.008000] Parcel 203 removed from outfeed 0\n",
      "[09:14:25.875000] Parcel 210 removed from outfeed 2\n",
      "[09:14:35.008000] Parcel 232 removed from outfeed 0\n",
      "[09:14:37.875000] Parcel 122 removed from outfeed 2\n",
      "[09:14:42.019000] Parcel 249 removed from outfeed 1\n",
      "[09:14:46.008000] Parcel 235 removed from outfeed 0\n",
      "[09:14:46.875000] Parcel 193 removed from outfeed 2\n",
      "[09:14:52.019000] Parcel 250 removed from outfeed 1\n",
      "[09:14:54.008000] Parcel 204 removed from outfeed 0\n",
      "[09:14:57.875000] Parcel 216 removed from outfeed 2\n",
      "[09:15:01.019000] Parcel 252 removed from outfeed 1\n",
      "[09:15:04.008000] Parcel 220 removed from outfeed 0\n",
      "[09:15:08.875000] Parcel 217 removed from outfeed 2\n",
      "[09:15:12.008000] Parcel 248 removed from outfeed 0\n",
      "[09:15:16.346000] Parcel 259 removed from outfeed 1\n",
      "[09:15:18.875000] Parcel 242 removed from outfeed 2\n",
      "[09:15:23.008000] Parcel 196 removed from outfeed 0\n",
      "[09:15:29.875000] Parcel 241 removed from outfeed 2\n",
      "[09:15:31.008000] Parcel 212 removed from outfeed 0\n",
      "[09:15:39.875000] Parcel 253 removed from outfeed 2\n",
      "[09:15:40.008000] Parcel 246 removed from outfeed 0\n",
      "[09:15:47.573000] Parcel 268 removed from outfeed 1\n",
      "[09:15:49.008000] Parcel 262 removed from outfeed 0\n",
      "[09:15:49.875000] Parcel 256 removed from outfeed 2\n",
      "[09:15:57.875000] Parcel 243 removed from outfeed 2\n",
      "[09:15:59.008000] Parcel 254 removed from outfeed 0\n",
      "[09:16:07.875000] Parcel 247 removed from outfeed 2\n",
      "[09:16:09.008000] Parcel 237 removed from outfeed 0\n",
      "[09:16:16.875000] Parcel 239 removed from outfeed 2\n",
      "[09:16:18.034000] Parcel 274 removed from outfeed 1\n",
      "[09:16:19.008000] Parcel 266 removed from outfeed 0\n",
      "[09:16:26.875000] Parcel 144 removed from outfeed 2\n",
      "[09:16:30.008000] Parcel 261 removed from outfeed 0\n",
      "[09:16:35.875000] Parcel 173 removed from outfeed 2\n",
      "[09:16:41.550000] Parcel 280 removed from outfeed 1\n",
      "[09:16:42.008000] Parcel 206 removed from outfeed 0\n",
      "[09:16:47.875000] Parcel 234 removed from outfeed 2\n",
      "[09:16:52.550000] Parcel 284 removed from outfeed 1\n",
      "[09:16:53.008000] Parcel 277 removed from outfeed 0\n",
      "[09:16:56.875000] Parcel 271 removed from outfeed 2\n",
      "[09:17:01.550000] Parcel 288 removed from outfeed 1\n",
      "[09:17:03.008000] Parcel 278 removed from outfeed 0\n",
      "[09:17:05.875000] Parcel 222 removed from outfeed 2\n",
      "[09:17:12.008000] Parcel 285 removed from outfeed 0\n",
      "[09:17:15.875000] Parcel 223 removed from outfeed 2\n",
      "[09:17:24.008000] Parcel 286 removed from outfeed 0\n",
      "[09:17:26.875000] Parcel 135 removed from outfeed 2\n",
      "[09:17:35.875000] Parcel 263 removed from outfeed 2\n",
      "[09:17:36.008000] Parcel 293 removed from outfeed 0\n",
      "[09:17:36.702000] Parcel 300 removed from outfeed 1\n",
      "[09:17:43.875000] Parcel 251 removed from outfeed 2\n",
      "[09:17:47.008000] Parcel 283 removed from outfeed 0\n",
      "[09:17:51.875000] Parcel 224 removed from outfeed 2\n",
      "[09:17:58.008000] Parcel 299 removed from outfeed 0\n",
      "[09:18:02.875000] Parcel 186 removed from outfeed 2\n",
      "[09:18:08.008000] Parcel 287 removed from outfeed 0\n",
      "[09:18:12.875000] Parcel 264 removed from outfeed 2\n",
      "[09:18:18.008000] Parcel 267 removed from outfeed 0\n",
      "[09:18:24.875000] Parcel 164 removed from outfeed 2\n",
      "[09:18:28.008000] Parcel 257 removed from outfeed 0\n",
      "[09:18:34.875000] Parcel 225 removed from outfeed 2\n",
      "[09:18:39.008000] Parcel 291 removed from outfeed 0\n",
      "[09:18:44.875000] Parcel 226 removed from outfeed 2\n",
      "[09:18:49.008000] Parcel 295 removed from outfeed 0\n",
      "[09:18:53.875000] Parcel 215 removed from outfeed 2\n",
      "[09:19:00.008000] Parcel 289 removed from outfeed 0\n",
      "[09:19:01.875000] Parcel 236 removed from outfeed 2\n",
      "[09:19:11.875000] Parcel 265 removed from outfeed 2\n",
      "[09:19:12.008000] Parcel 258 removed from outfeed 0\n",
      "[09:19:21.875000] Parcel 276 removed from outfeed 2\n",
      "[09:19:23.008000] Parcel 270 removed from outfeed 0\n",
      "[09:19:31.875000] Parcel 269 removed from outfeed 2\n",
      "[09:19:42.875000] Parcel 195 removed from outfeed 2\n",
      "[09:19:51.875000] Parcel 260 removed from outfeed 2\n",
      "[09:20:02.875000] Parcel 181 removed from outfeed 2\n",
      "[09:20:13.875000] Parcel 279 removed from outfeed 2\n",
      "[09:20:23.875000] Parcel 294 removed from outfeed 2\n",
      "[09:20:35.875000] Parcel 244 removed from outfeed 2\n",
      "[09:20:45.875000] Parcel 275 removed from outfeed 2\n",
      "[09:20:55.875000] Parcel 245 removed from outfeed 2\n",
      "[09:21:06.875000] Parcel 290 removed from outfeed 2\n",
      "[09:21:17.875000] Parcel 281 removed from outfeed 2\n",
      "[09:21:28.875000] Parcel 282 removed from outfeed 2\n",
      "[09:21:38.875000] Parcel 272 removed from outfeed 2\n",
      "[09:21:47.875000] Parcel 296 removed from outfeed 2\n",
      "[09:21:57.875000] Parcel 297 removed from outfeed 2\n",
      "[09:22:08.875000] Parcel 298 removed from outfeed 2\n",
      "[09:22:18.875000] Parcel 273 removed from outfeed 2\n",
      "[09:22:28.875000] Parcel 255 removed from outfeed 2\n",
      "\n",
      "Total parcels processed: 293\n",
      "Parcels recirculated: 499\n",
      "Success rate (no recirc on first pass): 53.92%\n",
      "Outfeed 0: 109 parcels, 37.20% of sorted\n",
      "Outfeed 1: 53 parcels, 18.09% of sorted\n",
      "Outfeed 2: 131 parcels, 44.71% of sorted\n",
      "Throughput (sorted + recirculated): 792\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# DATA CLEANING FUNCTIONS\n",
    "# --------------------------------------------------------------------------\n",
    "def remove_outliers_iqr(df, cols):\n",
    "    for c in cols:\n",
    "        Q1, Q3 = df[c].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        df = df[df[c].between(Q1 - 2 * IQR, Q3 + 2 * IQR)]\n",
    "    return df\n",
    "\n",
    "def drop_rows_without_true_outfeed(df, prefix=\"Outfeed\"):\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    return df[df[cols].any(axis=1)] if cols else df\n",
    "\n",
    "def clean_parcel_data(df):\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    df = remove_outliers_iqr(df, [\"Length\", \"Width\", \"Height\"])\n",
    "    df = drop_rows_without_true_outfeed(df)\n",
    "    return df\n",
    "\n",
    "def load_parcels_from_clean_df(df):\n",
    "    parcels = []\n",
    "    for _, r in df.iterrows():\n",
    "        parcels.append(Parcel(\n",
    "            pid=int(r[\"Parcel Number\"]),\n",
    "            arrival_time=pd.to_datetime(r[\"Arrival Time\"]),\n",
    "            length=float(r[\"Length\"]),\n",
    "            width=float(r[\"Width\"]),\n",
    "            height=float(r[\"Height\"]),\n",
    "            weight=float(r[\"Weight\"]),\n",
    "            feasible=[i for i, f in enumerate(\n",
    "                [r[\"Outfeed 1\"], r[\"Outfeed 2\"], r[\"Outfeed 3\"]]) if f]\n",
    "        ))\n",
    "    return sorted(parcels, key=lambda p: p.arrival_time)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# EVENT, FES, PARCEL\n",
    "# --------------------------------------------------------------------------\n",
    "class Event:\n",
    "    ARRIVAL = 0\n",
    "    ENTER_SCANNER = 1\n",
    "    ENTER_OUTFEED = 2\n",
    "    EXIT_OUTFEED = 3\n",
    "    RECIRCULATE = 4\n",
    "    def __init__(self, typ, time, parcel, outfeed_id=None): # type is a reserved word\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        param1 (typ): What type of event it is, e.g, Arrival, scanner...\n",
    "        param2 (time): at what time the event occurs.\n",
    "        param3 (parcel): all the information of the parcel that is being processed.\n",
    "        param4 (outfeed_id): the outfeed to which the parcel goes. It is an optional parameter since it is only needed for events 2 and 3.\n",
    "        \"\"\"\n",
    "        self.type = typ\n",
    "        self.time = time  # float: seconds since t0\n",
    "        self.parcel = parcel\n",
    "        self.outfeed_id = outfeed_id # Only used for ENTER_OUTFEED and EXIT_OUTFEED events\n",
    "    def __lt__(self, other):\n",
    "        return self.time < other.time\n",
    "\n",
    "class FES:\n",
    "    \"\"\"\n",
    "    Future Event Set (FES) for discrete event simulation.\n",
    "    This class uses a priority queue to manage events in the simulation.\n",
    "    Events are sorted by their time attribute, which is a float.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.events = []\n",
    "    def add(self, event):\n",
    "        heapq.heappush(self.events, event)\n",
    "    def next(self):\n",
    "        return heapq.heappop(self.events)\n",
    "    def isEmpty(self):\n",
    "        return len(self.events) == 0\n",
    "\n",
    "class Parcel: #This replicates the Customer class, in which info about the customers (parcels) is stored.\n",
    "    def __init__(self, pid, arrival_time, length, width, height, weight, feasible):\n",
    "        self.id = pid\n",
    "        self.arrival_time = arrival_time\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        self.feasible_outfeeds = feasible\n",
    "        self.sorted = False\n",
    "        self.recirculated = False\n",
    "        self.outfeed_attempts = [] #Afterwards, makes a copy of the feasible outfeeds of the parcel. Used for the algorithm functioning.\n",
    "        self.recirculation_count = 0\n",
    "\n",
    "    def get_volume(self):\n",
    "        return self.length * self.width * self.height\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# OUTFEED MODEL\n",
    "# --------------------------------------------------------------------------\n",
    "def compute_outfeed_time(parcel):\n",
    "    base_time = 8\n",
    "\n",
    "    # Volume classes\n",
    "    volume = parcel.get_volume()\n",
    "    if volume < 0.035:\n",
    "        volume_class_delay = 0\n",
    "    elif volume < 0.055:\n",
    "        volume_class_delay = 1\n",
    "    else:\n",
    "        volume_class_delay = 2\n",
    "\n",
    "    # Weight classes\n",
    "    weight = parcel.weight\n",
    "    if weight < 1700:\n",
    "        weight_class_delay = 0\n",
    "    elif weight < 2800:\n",
    "        weight_class_delay = 1\n",
    "    else:\n",
    "        weight_class_delay = 2\n",
    "\n",
    "    return base_time + volume_class_delay + weight_class_delay\n",
    "\n",
    "#Probably not to be used in this code, I leave it here now just in case, but the outfeed functioning goes in the simualation class.\n",
    "class Outfeed:\n",
    "    def __init__(self, max_length=3.0):\n",
    "        self.max_length = max_length\n",
    "        self.current_length = 0.0\n",
    "        self.queue = []   # list of (Parcel, service_time)\n",
    "        self.next_time = 0.0\n",
    "    \n",
    "    def can_accept(self, parcel):\n",
    "        return self.current_length + parcel.length <= self.max_length\n",
    "    \n",
    "    def add_parcel(self, parcel):\n",
    "        t = compute_outfeed_time(parcel)\n",
    "        self.queue.append((parcel, t))\n",
    "        self.current_length += parcel.length\n",
    "        if len(self.queue) == 1:\n",
    "            #Timer for the current parcel \n",
    "            self.next_time = t\n",
    "    \n",
    "    def update(self, dt):\n",
    "        self.next_time -= dt\n",
    "        if self.next_time <= 0 and self.queue:\n",
    "            p, _ = self.queue.pop(0)\n",
    "            self.current_length -= p.length\n",
    "            if self.queue:\n",
    "                #Timer for the next parcel in line\n",
    "                self.next_time = self.queue[0][1]\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# POSISORTER with Windowed Local Search + Logging + Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "class PosiSorterSystem:\n",
    "    REBALANCE_INTERVAL = 1      # run hill-climb every N arrivals\n",
    "\n",
    "    def __init__(self, layout_df): #Not sure if i should add arrdist or something similar here.\n",
    "\n",
    "        L = layout_df.set_index(\"Layout property\")[\"Value\"]\n",
    "        self.belt_speed = L[\"Belt Speed\"]\n",
    "        self.d_in_sc = L[\"Distance Infeeds to Scanner\"]\n",
    "        self.d_sc_of = L[\"Distance Scanner to Outfeeds\"]\n",
    "        self.d_between = L[\"Distance between Outfeeds\"]\n",
    "        self.d_of_in = L[\"Distance Outfeeds to Infeeds\"]\n",
    "        self.num_outfeeds = 3 # Given in Excel sheet. Can be automatically detected from the layout_df if needed.\n",
    "        self.outfeeds = [Outfeed(max_length=3.0) for _ in range(self.num_outfeeds)]\n",
    "        #These are used to print statistics about the system:\n",
    "        self.recirculated_count = 0\n",
    "        self.outfeed_counts = [0] * self.num_outfeeds\n",
    "        self.total_processed = 0\n",
    "        self.first_pass_failures = set()\n",
    "        # Greedy + periodic windowed local search\n",
    "        self.loads = {k: 0.0 for k in range(self.num_outfeeds)}   # tracked load per outfeed\n",
    "        self.service_times = {}\n",
    "        self.assignment = {}                                      # parcel.id -> outfeed or None\n",
    "        self.WINDOW_DURATION = self.d_sc_of /self.belt_speed      # Time stamp of window in seconds\n",
    "        self.window = deque()              \n",
    "        self.rebal_ctr = 0\n",
    "    \n",
    "    def greedy(self, p):\n",
    "        feas = [k for k in p.feasible_outfeeds if self.outfeeds[k].can_accept(p)]\n",
    "        if not feas: return None\n",
    "        return min(feas, key=lambda k: self.loads[k])\n",
    "\n",
    "    def imbalance(self, loads):\n",
    "        # Objective: load spread between heaviest and lightest outfeed\n",
    "        return max(loads.values()) - min(loads.values())\n",
    "\n",
    "    def run_local_search(self, max_iters=100):\n",
    "        loads = self.loads.copy()\n",
    "        assign_w = {}\n",
    "        # assign window packets greedily by current load\n",
    "        for _, p in self.window:\n",
    "            k = self.greedy(p)\n",
    "            assign_w[p.id] = k\n",
    "            if k is not None:\n",
    "                loads[k] += self.service_times.get(p.id, 0)\n",
    "        # hill-climb\n",
    "        for _ in range(max_iters):\n",
    "            improved = False\n",
    "            for _, p in self.window:\n",
    "                cur = assign_w[p.id]\n",
    "                for k in p.feasible_outfeeds:\n",
    "                    if k == cur or not self.outfeeds[k].can_accept(p): continue\n",
    "                    st = self.service_times.get(p.id, 0)\n",
    "                    new_loads = loads.copy()\n",
    "                    if cur is not None: new_loads[cur] -= st\n",
    "                    new_loads[k] += st\n",
    "                    if self.imbalance(new_loads) < self.imbalance(loads):\n",
    "                        loads, assign_w[p.id] = new_loads, k\n",
    "                        improved = True\n",
    "                        break\n",
    "                if improved: break\n",
    "            if not improved: break\n",
    "        for pid, k in assign_w.items():\n",
    "            self.assignment[pid] = k\n",
    "\n",
    "    def handle_enter_scanner(self, evt, fes):\n",
    "        p = evt.parcel\n",
    "        # 1) greedy assign\n",
    "        k0 = self.greedy(p)\n",
    "        self.assignment[p.id] = k0\n",
    "        # track failure on first pass\n",
    "        if k0 is None:\n",
    "            self.first_pass_failures.add(p.id)\n",
    "        # 2) window and rebalance\n",
    "        self.window.append((evt.time, p))\n",
    "        # Remove parcels outside the window\n",
    "        while self.window and evt.time - self.window[0][0] > self.WINDOW_DURATION:\n",
    "            self.window.popleft()\n",
    "        self.rebal_ctr += 1\n",
    "        if self.rebal_ctr >= self.REBALANCE_INTERVAL:\n",
    "            self.run_local_search()\n",
    "            self.rebal_ctr = 0\n",
    "        # 3) schedule\n",
    "        t = evt.time\n",
    "        if self.assignment[p.id] is None:\n",
    "            # No feasible outfeed: recirculate\n",
    "            self.recirculated_count += 1\n",
    "            dt = (self.d_sc_of + self.d_between * self.num_outfeeds) / self.belt_speed\n",
    "            fes.add(Event(Event.RECIRCULATE, t + dt, p))\n",
    "        else:\n",
    "            # Schedule entering chosen outfeed\n",
    "            k = self.assignment[p.id]\n",
    "            dt = (self.d_sc_of + k * self.d_between) / self.belt_speed\n",
    "            fes.add(Event(Event.ENTER_OUTFEED, t + dt, p, outfeed_id=k))\n",
    "\n",
    "    def simulate(self, parcels):\n",
    "        fes = FES()\n",
    "        t = 0\n",
    "        t0 = parcels[0].arrival_time #We need to convert the arrival time to seconds, since the rest of the times are in seconds.\n",
    "        #With this for loop, we initiate the simulation by adding all the arrival events of the excel file to the FES. It might not be the most efficient way, \n",
    "        # but I think it works since anyways, the events are sorted by time in the FES afterwards.\n",
    "        for p in parcels:\n",
    "            t = (p.arrival_time - t0).total_seconds()\n",
    "            fes.add(Event(Event.ARRIVAL, t, p)) # schedule the event\n",
    "        while not fes.isEmpty(): # T is still to be determined\n",
    "            told = t #not being used right now, ususally used to store waiting times.\n",
    "            evt = fes.next() #retrieve the next event in the FES and removes it\n",
    "            t = evt.time\n",
    "            if evt.type == Event.ARRIVAL:\n",
    "                fes.add(Event(Event.ENTER_SCANNER, evt.time + self.d_in_sc / self.belt_speed, evt.parcel))\n",
    "            ### Handle outfeed events based on the load balacing and local search\n",
    "            elif evt.type == Event.ENTER_SCANNER:\n",
    "                self.handle_enter_scanner(evt, fes)\n",
    "            elif evt.type == Event.ENTER_OUTFEED:\n",
    "                k, p = evt.outfeed_id, evt.parcel\n",
    "                f = self.outfeeds[k]\n",
    "                f.add_parcel(p)\n",
    "                self.outfeed_counts[k] += 1\n",
    "                self.loads[k] += p.length\n",
    "                if len(f.queue) == 1:\n",
    "                    fes.add(Event(\n",
    "                        Event.EXIT_OUTFEED,\n",
    "                        evt.time + f.queue[0][1],\n",
    "                        p, outfeed_id=k\n",
    "                    ))\n",
    "            elif evt.type == Event.EXIT_OUTFEED:\n",
    "                k, p = evt.outfeed_id, evt.parcel\n",
    "                f = self.outfeeds[k]\n",
    "                f.update(f.next_time)\n",
    "                self.loads[k] -= p.length\n",
    "                actual_time = t0 + timedelta(seconds=evt.time)\n",
    "                print(f\"[{actual_time.time()}] Parcel {p.id} removed from outfeed {k}\")\n",
    "                if f.queue:\n",
    "                    fes.add(Event(\n",
    "                        Event.EXIT_OUTFEED,\n",
    "                        evt.time + f.queue[0][1],\n",
    "                        f.queue[0][0], outfeed_id=k\n",
    "                    ))\n",
    "            elif evt.type == Event.RECIRCULATE:\n",
    "                fes.add(Event(\n",
    "                    Event.ENTER_SCANNER,\n",
    "                    evt.time + (self.d_of_in + self.d_in_sc) / self.belt_speed,\n",
    "                    evt.parcel\n",
    "                ))\n",
    "        # final summary\n",
    "        total = len(parcels)\n",
    "        sorted_total = sum(self.outfeed_counts)\n",
    "        success_rate = (total - len(self.first_pass_failures)) / total * 100\n",
    "        print()\n",
    "        print(f\"Total parcels processed: {len(parcels)}\")\n",
    "        print(f\"Parcels recirculated: {self.recirculated_count}\")\n",
    "        print(f\"Success rate (no recirc on first pass): {success_rate:.2f}%\")\n",
    "        for i, cnt in enumerate(self.outfeed_counts):\n",
    "            pct = cnt / sorted_total * 100 if sorted_total > 0 else 0\n",
    "            print(f\"Outfeed {i}: {cnt} parcels, {pct:.2f}% of sorted\")\n",
    "        print(f\"Throughput (sorted + recirculated): {sorted_total + self.recirculated_count}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# MAIN\n",
    "# ----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    xls = pd.ExcelFile(\"PosiSorterData1.xlsx\")\n",
    "    df_p = clean_parcel_data(xls.parse(\"Parcels\"))\n",
    "    df_l = xls.parse(\"Layout\")\n",
    "    parcels = load_parcels_from_clean_df(df_p)\n",
    "    system = PosiSorterSystem(df_l)\n",
    "    system.simulate(parcels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
