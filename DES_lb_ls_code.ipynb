{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e341f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:00:19.337000] Parcel 1 removed from outfeed 0\n",
      "[09:00:25.837000] Parcel 2 removed from outfeed 0\n",
      "[09:00:26.375000] Parcel 16 removed from outfeed 2\n",
      "[09:00:32.875000] Parcel 149 removed from outfeed 2\n",
      "[09:00:33.057000] Parcel 3 removed from outfeed 0\n",
      "[09:00:38.557000] Parcel 4 removed from outfeed 0\n",
      "[09:00:39.375000] Parcel 133 removed from outfeed 2\n",
      "[09:00:45.057000] Parcel 5 removed from outfeed 0\n",
      "[09:00:49.789000] Parcel 6 removed from outfeed 2\n",
      "[09:00:52.557000] Parcel 7 removed from outfeed 0\n",
      "[09:00:53.727000] Parcel 9 removed from outfeed 1\n",
      "[09:00:59.227000] Parcel 10 removed from outfeed 1\n",
      "[09:01:00.887000] Parcel 11 removed from outfeed 2\n",
      "[09:01:01.057000] Parcel 8 removed from outfeed 0\n",
      "[09:01:05.387000] Parcel 12 removed from outfeed 2\n",
      "[09:01:08.557000] Parcel 14 removed from outfeed 0\n",
      "[09:01:18.589000] Parcel 15 removed from outfeed 2\n",
      "[09:01:21.202000] Parcel 19 removed from outfeed 0\n",
      "[09:01:25.089000] Parcel 17 removed from outfeed 2\n",
      "[09:01:29.589000] Parcel 18 removed from outfeed 2\n",
      "[09:01:35.089000] Parcel 20 removed from outfeed 2\n",
      "[09:01:43.589000] Parcel 21 removed from outfeed 2\n",
      "[09:01:46.539000] Parcel 25 removed from outfeed 0\n",
      "[09:01:51.089000] Parcel 22 removed from outfeed 2\n",
      "[09:01:52.039000] Parcel 27 removed from outfeed 0\n",
      "[09:01:55.605000] Parcel 29 removed from outfeed 1\n",
      "[09:01:56.589000] Parcel 23 removed from outfeed 2\n",
      "[09:02:00.539000] Parcel 28 removed from outfeed 0\n",
      "[09:02:05.089000] Parcel 24 removed from outfeed 2\n",
      "[09:02:07.039000] Parcel 31 removed from outfeed 0\n",
      "[09:02:12.627000] Parcel 33 removed from outfeed 1\n",
      "[09:02:13.278000] Parcel 35 removed from outfeed 0\n",
      "[09:02:15.581000] Parcel 32 removed from outfeed 2\n",
      "[09:02:23.568000] Parcel 38 removed from outfeed 1\n",
      "[09:02:24.081000] Parcel 34 removed from outfeed 2\n",
      "[09:02:29.581000] Parcel 36 removed from outfeed 2\n",
      "[09:02:31.872000] Parcel 42 removed from outfeed 0\n",
      "[09:02:37.372000] Parcel 43 removed from outfeed 0\n",
      "[09:02:38.081000] Parcel 37 removed from outfeed 2\n",
      "[09:02:44.110000] Parcel 46 removed from outfeed 0\n",
      "[09:02:46.581000] Parcel 39 removed from outfeed 2\n",
      "[09:02:49.610000] Parcel 47 removed from outfeed 0\n",
      "[09:02:54.081000] Parcel 40 removed from outfeed 2\n",
      "[09:02:58.581000] Parcel 41 removed from outfeed 2\n",
      "[09:03:00.901000] Parcel 52 removed from outfeed 0\n",
      "[09:03:01.692000] Parcel 51 removed from outfeed 1\n",
      "[09:03:05.401000] Parcel 53 removed from outfeed 0\n",
      "[09:03:06.081000] Parcel 48 removed from outfeed 2\n",
      "[09:03:10.382000] Parcel 55 removed from outfeed 1\n",
      "[09:03:13.581000] Parcel 49 removed from outfeed 2\n",
      "[09:03:16.805000] Parcel 56 removed from outfeed 0\n",
      "[09:03:19.081000] Parcel 50 removed from outfeed 2\n",
      "[09:03:27.581000] Parcel 54 removed from outfeed 2\n",
      "[09:03:28.537000] Parcel 58 removed from outfeed 0\n",
      "[09:03:36.081000] Parcel 44 removed from outfeed 2\n",
      "[09:03:41.990000] Parcel 62 removed from outfeed 1\n",
      "[09:03:42.581000] Parcel 45 removed from outfeed 2\n",
      "[09:03:48.490000] Parcel 64 removed from outfeed 1\n",
      "[09:03:49.081000] Parcel 57 removed from outfeed 2\n",
      "[09:03:55.581000] Parcel 60 removed from outfeed 2\n",
      "[09:04:01.336000] Parcel 67 removed from outfeed 0\n",
      "[09:04:04.081000] Parcel 63 removed from outfeed 2\n",
      "[09:04:09.581000] Parcel 68 removed from outfeed 2\n",
      "[09:04:18.081000] Parcel 59 removed from outfeed 2\n",
      "[09:04:24.581000] Parcel 69 removed from outfeed 2\n",
      "[09:04:32.896000] Parcel 74 removed from outfeed 1\n",
      "[09:04:33.081000] Parcel 70 removed from outfeed 2\n",
      "[09:04:39.581000] Parcel 61 removed from outfeed 2\n",
      "[09:04:41.508000] Parcel 78 removed from outfeed 0\n",
      "[09:04:43.227000] Parcel 77 removed from outfeed 1\n",
      "[09:04:44.081000] Parcel 71 removed from outfeed 2\n",
      "[09:04:47.727000] Parcel 80 removed from outfeed 1\n",
      "[09:04:48.008000] Parcel 79 removed from outfeed 0\n",
      "[09:04:50.581000] Parcel 72 removed from outfeed 2\n",
      "[09:04:55.508000] Parcel 81 removed from outfeed 0\n",
      "[09:04:58.081000] Parcel 73 removed from outfeed 2\n",
      "[09:05:00.008000] Parcel 84 removed from outfeed 0\n",
      "[09:05:04.030000] Parcel 83 removed from outfeed 1\n",
      "[09:05:05.659000] Parcel 82 removed from outfeed 2\n",
      "[09:05:10.143000] Parcel 85 removed from outfeed 0\n",
      "[09:05:13.159000] Parcel 65 removed from outfeed 2\n",
      "[09:05:16.643000] Parcel 86 removed from outfeed 0\n",
      "[09:05:19.659000] Parcel 66 removed from outfeed 2\n",
      "[09:05:27.159000] Parcel 76 removed from outfeed 2\n",
      "[09:05:31.774000] Parcel 90 removed from outfeed 0\n",
      "[09:05:35.659000] Parcel 87 removed from outfeed 2\n",
      "[09:05:36.610000] Parcel 91 removed from outfeed 1\n",
      "[09:05:41.716000] Parcel 93 removed from outfeed 0\n",
      "[09:05:42.159000] Parcel 88 removed from outfeed 2\n",
      "[09:05:43.110000] Parcel 92 removed from outfeed 1\n",
      "[09:05:48.216000] Parcel 94 removed from outfeed 0\n",
      "[09:05:48.610000] Parcel 96 removed from outfeed 1\n",
      "[09:05:48.659000] Parcel 89 removed from outfeed 2\n",
      "[09:05:55.159000] Parcel 95 removed from outfeed 2\n",
      "[09:05:56.930000] Parcel 99 removed from outfeed 0\n",
      "[09:05:57.110000] Parcel 97 removed from outfeed 1\n",
      "[09:06:02.659000] Parcel 98 removed from outfeed 2\n",
      "[09:06:09.403000] Parcel 101 removed from outfeed 0\n",
      "[09:06:10.159000] Parcel 100 removed from outfeed 2\n",
      "[09:06:17.903000] Parcel 102 removed from outfeed 0\n",
      "[09:06:20.556000] Parcel 107 removed from outfeed 1\n",
      "[09:06:22.879000] Parcel 105 removed from outfeed 2\n",
      "[09:06:26.403000] Parcel 104 removed from outfeed 0\n",
      "[09:06:32.122000] Parcel 108 removed from outfeed 1\n",
      "[09:06:32.903000] Parcel 106 removed from outfeed 0\n",
      "[09:06:34.148000] Parcel 109 removed from outfeed 2\n",
      "[09:06:41.648000] Parcel 110 removed from outfeed 2\n",
      "[09:06:44.677000] Parcel 115 removed from outfeed 0\n",
      "[09:06:46.148000] Parcel 111 removed from outfeed 2\n",
      "[09:06:50.648000] Parcel 112 removed from outfeed 2\n",
      "[09:06:51.152000] Parcel 117 removed from outfeed 0\n",
      "[09:06:56.148000] Parcel 113 removed from outfeed 2\n",
      "[09:07:03.648000] Parcel 114 removed from outfeed 2\n",
      "[09:07:07.936000] Parcel 120 removed from outfeed 0\n",
      "[09:07:11.148000] Parcel 116 removed from outfeed 2\n",
      "[09:07:15.635000] Parcel 123 removed from outfeed 0\n",
      "[09:07:15.648000] Parcel 119 removed from outfeed 2\n",
      "[09:07:23.148000] Parcel 121 removed from outfeed 2\n",
      "[09:07:25.985000] Parcel 126 removed from outfeed 0\n",
      "[09:07:31.648000] Parcel 122 removed from outfeed 2\n",
      "[09:07:34.485000] Parcel 127 removed from outfeed 0\n",
      "[09:07:37.148000] Parcel 124 removed from outfeed 2\n",
      "[09:07:42.648000] Parcel 125 removed from outfeed 2\n",
      "[09:07:43.219000] Parcel 131 removed from outfeed 0\n",
      "[09:07:49.148000] Parcel 118 removed from outfeed 2\n",
      "[09:07:50.719000] Parcel 132 removed from outfeed 0\n",
      "[09:07:55.648000] Parcel 129 removed from outfeed 2\n",
      "[09:07:56.369000] Parcel 134 removed from outfeed 0\n",
      "[09:08:02.148000] Parcel 130 removed from outfeed 2\n",
      "[09:08:07.084000] Parcel 137 removed from outfeed 0\n",
      "[09:08:07.481000] Parcel 136 removed from outfeed 1\n",
      "[09:08:09.648000] Parcel 135 removed from outfeed 2\n",
      "[09:08:12.584000] Parcel 139 removed from outfeed 0\n",
      "[09:08:18.148000] Parcel 128 removed from outfeed 2\n",
      "[09:08:19.084000] Parcel 140 removed from outfeed 0\n",
      "[09:08:23.648000] Parcel 138 removed from outfeed 2\n",
      "[09:08:23.720000] Parcel 141 removed from outfeed 1\n",
      "[09:08:25.584000] Parcel 142 removed from outfeed 0\n",
      "[09:08:32.861000] Parcel 143 removed from outfeed 2\n",
      "[09:08:37.375000] Parcel 146 removed from outfeed 0\n",
      "[09:08:39.361000] Parcel 144 removed from outfeed 2\n",
      "[09:08:43.861000] Parcel 145 removed from outfeed 2\n",
      "[09:08:44.875000] Parcel 147 removed from outfeed 0\n",
      "[09:08:50.375000] Parcel 150 removed from outfeed 0\n",
      "[09:08:52.361000] Parcel 148 removed from outfeed 2\n",
      "[09:08:55.875000] Parcel 151 removed from outfeed 0\n",
      "[09:09:00.017000] Parcel 152 removed from outfeed 2\n",
      "[09:09:06.517000] Parcel 153 removed from outfeed 2\n",
      "[09:09:07.774000] Parcel 155 removed from outfeed 0\n",
      "[09:09:13.017000] Parcel 154 removed from outfeed 2\n",
      "[09:09:13.123000] Parcel 156 removed from outfeed 1\n",
      "[09:09:16.695000] Parcel 157 removed from outfeed 0\n",
      "[09:09:25.051000] Parcel 159 removed from outfeed 0\n",
      "[09:09:25.477000] Parcel 158 removed from outfeed 2\n",
      "[09:09:36.724000] Parcel 160 removed from outfeed 0\n",
      "[09:09:45.972000] Parcel 161 removed from outfeed 2\n",
      "[09:09:47.810000] Parcel 162 removed from outfeed 1\n",
      "[09:09:48.881000] Parcel 163 removed from outfeed 0\n",
      "[09:10:00.902000] Parcel 164 removed from outfeed 2\n",
      "[09:10:01.898000] Parcel 165 removed from outfeed 0\n",
      "[09:10:07.878000] Parcel 166 removed from outfeed 2\n",
      "[09:10:10.010000] Parcel 167 removed from outfeed 0\n",
      "[09:10:17.510000] Parcel 169 removed from outfeed 0\n",
      "[09:10:19.549000] Parcel 170 removed from outfeed 1\n",
      "[09:10:21.514000] Parcel 168 removed from outfeed 2\n",
      "[09:10:25.010000] Parcel 171 removed from outfeed 0\n",
      "[09:10:25.568000] Parcel 174 removed from outfeed 1\n",
      "[09:10:28.472000] Parcel 173 removed from outfeed 2\n",
      "[09:10:31.510000] Parcel 172 removed from outfeed 0\n",
      "[09:10:33.972000] Parcel 175 removed from outfeed 2\n",
      "[09:10:38.655000] Parcel 176 removed from outfeed 1\n",
      "[09:10:41.026000] Parcel 177 removed from outfeed 2\n",
      "[09:10:44.338000] Parcel 180 removed from outfeed 0\n",
      "[09:10:48.592000] Parcel 179 removed from outfeed 1\n",
      "[09:10:49.526000] Parcel 178 removed from outfeed 2\n",
      "[09:10:59.976000] Parcel 182 removed from outfeed 1\n",
      "[09:11:00.737000] Parcel 183 removed from outfeed 0\n",
      "[09:11:04.047000] Parcel 181 removed from outfeed 2\n",
      "[09:11:05.476000] Parcel 184 removed from outfeed 1\n",
      "[09:11:09.976000] Parcel 185 removed from outfeed 1\n",
      "[09:11:11.144000] Parcel 188 removed from outfeed 0\n",
      "[09:11:11.635000] Parcel 186 removed from outfeed 2\n",
      "[09:11:16.238000] Parcel 189 removed from outfeed 1\n",
      "[09:11:18.135000] Parcel 187 removed from outfeed 2\n",
      "[09:11:25.792000] Parcel 191 removed from outfeed 0\n",
      "[09:11:26.777000] Parcel 190 removed from outfeed 2\n",
      "[09:11:30.762000] Parcel 192 removed from outfeed 1\n",
      "[09:11:33.292000] Parcel 194 removed from outfeed 0\n",
      "[09:11:34.779000] Parcel 193 removed from outfeed 2\n",
      "[09:11:39.517000] Parcel 197 removed from outfeed 1\n",
      "[09:11:40.792000] Parcel 196 removed from outfeed 0\n",
      "[09:11:42.279000] Parcel 195 removed from outfeed 2\n",
      "[09:11:47.292000] Parcel 198 removed from outfeed 0\n",
      "[09:11:49.779000] Parcel 200 removed from outfeed 2\n",
      "[09:11:55.279000] Parcel 201 removed from outfeed 2\n",
      "[09:11:55.792000] Parcel 199 removed from outfeed 0\n",
      "[09:11:59.973000] Parcel 208 removed from outfeed 1\n",
      "[09:12:00.779000] Parcel 202 removed from outfeed 2\n",
      "[09:12:01.292000] Parcel 203 removed from outfeed 0\n",
      "[09:12:05.792000] Parcel 204 removed from outfeed 0\n",
      "[09:12:07.279000] Parcel 205 removed from outfeed 2\n",
      "[09:12:12.779000] Parcel 210 removed from outfeed 2\n",
      "[09:12:14.169000] Parcel 211 removed from outfeed 1\n",
      "[09:12:14.292000] Parcel 206 removed from outfeed 0\n",
      "[09:12:19.792000] Parcel 209 removed from outfeed 0\n",
      "[09:12:24.292000] Parcel 212 removed from outfeed 0\n",
      "[09:12:26.172000] Parcel 215 removed from outfeed 2\n",
      "[09:12:29.792000] Parcel 213 removed from outfeed 0\n",
      "[09:12:33.672000] Parcel 216 removed from outfeed 2\n",
      "[09:12:38.292000] Parcel 214 removed from outfeed 0\n",
      "[09:12:41.172000] Parcel 217 removed from outfeed 2\n",
      "[09:12:44.265000] Parcel 219 removed from outfeed 1\n",
      "[09:12:45.776000] Parcel 220 removed from outfeed 0\n",
      "[09:12:47.672000] Parcel 218 removed from outfeed 2\n",
      "[09:12:54.172000] Parcel 221 removed from outfeed 2\n",
      "[09:12:59.672000] Parcel 222 removed from outfeed 2\n",
      "[09:13:03.972000] Parcel 227 removed from outfeed 1\n",
      "[09:13:06.172000] Parcel 223 removed from outfeed 2\n",
      "[09:13:08.472000] Parcel 228 removed from outfeed 1\n",
      "[09:13:10.672000] Parcel 224 removed from outfeed 2\n",
      "[09:13:17.172000] Parcel 225 removed from outfeed 2\n",
      "[09:13:20.116000] Parcel 232 removed from outfeed 0\n",
      "[09:13:23.672000] Parcel 226 removed from outfeed 2\n",
      "[09:13:25.616000] Parcel 233 removed from outfeed 0\n",
      "[09:13:28.172000] Parcel 230 removed from outfeed 2\n",
      "[09:13:34.179000] Parcel 235 removed from outfeed 0\n",
      "[09:13:36.672000] Parcel 231 removed from outfeed 2\n",
      "[09:13:42.781000] Parcel 237 removed from outfeed 0\n",
      "[09:13:45.172000] Parcel 234 removed from outfeed 2\n",
      "[09:13:49.672000] Parcel 236 removed from outfeed 2\n",
      "[09:13:56.172000] Parcel 229 removed from outfeed 2\n",
      "[09:13:56.720000] Parcel 238 removed from outfeed 0\n",
      "[09:14:02.121000] Parcel 239 removed from outfeed 2\n",
      "[09:14:13.176000] Parcel 240 removed from outfeed 1\n",
      "[09:14:21.276000] Parcel 241 removed from outfeed 2\n",
      "[09:14:28.072000] Parcel 242 removed from outfeed 2\n",
      "[09:14:28.549000] Parcel 246 removed from outfeed 0\n",
      "[09:14:32.572000] Parcel 243 removed from outfeed 2\n",
      "[09:14:33.944000] Parcel 248 removed from outfeed 0\n",
      "[09:14:38.519000] Parcel 249 removed from outfeed 1\n",
      "[09:14:41.072000] Parcel 244 removed from outfeed 2\n",
      "[09:14:45.311000] Parcel 250 removed from outfeed 1\n",
      "[09:14:47.572000] Parcel 245 removed from outfeed 2\n",
      "[09:14:50.811000] Parcel 252 removed from outfeed 1\n",
      "[09:14:53.818000] Parcel 254 removed from outfeed 0\n",
      "[09:14:54.072000] Parcel 247 removed from outfeed 2\n",
      "[09:14:58.572000] Parcel 251 removed from outfeed 2\n",
      "[09:15:01.983000] Parcel 257 removed from outfeed 0\n",
      "[09:15:05.072000] Parcel 253 removed from outfeed 2\n",
      "[09:15:10.483000] Parcel 258 removed from outfeed 0\n",
      "[09:15:11.572000] Parcel 255 removed from outfeed 2\n",
      "[09:15:12.846000] Parcel 259 removed from outfeed 1\n",
      "[09:15:17.983000] Parcel 261 removed from outfeed 0\n",
      "[09:15:18.072000] Parcel 256 removed from outfeed 2\n",
      "[09:15:23.483000] Parcel 262 removed from outfeed 0\n",
      "[09:15:23.572000] Parcel 260 removed from outfeed 2\n",
      "[09:15:29.072000] Parcel 263 removed from outfeed 2\n",
      "[09:15:33.366000] Parcel 266 removed from outfeed 0\n",
      "[09:15:35.572000] Parcel 264 removed from outfeed 2\n",
      "[09:15:39.866000] Parcel 267 removed from outfeed 0\n",
      "[09:15:42.072000] Parcel 265 removed from outfeed 2\n",
      "[09:15:44.073000] Parcel 268 removed from outfeed 1\n",
      "[09:15:50.729000] Parcel 270 removed from outfeed 0\n",
      "[09:15:53.901000] Parcel 269 removed from outfeed 2\n",
      "[09:15:59.401000] Parcel 271 removed from outfeed 2\n",
      "[09:16:11.519000] Parcel 272 removed from outfeed 2\n",
      "[09:16:14.534000] Parcel 274 removed from outfeed 1\n",
      "[09:16:18.065000] Parcel 273 removed from outfeed 2\n",
      "[09:16:23.493000] Parcel 277 removed from outfeed 0\n",
      "[09:16:24.565000] Parcel 275 removed from outfeed 2\n",
      "[09:16:29.993000] Parcel 278 removed from outfeed 0\n",
      "[09:16:31.065000] Parcel 276 removed from outfeed 2\n",
      "[09:16:38.050000] Parcel 280 removed from outfeed 1\n",
      "[09:16:38.406000] Parcel 283 removed from outfeed 0\n",
      "[09:16:38.565000] Parcel 279 removed from outfeed 2\n",
      "[09:16:44.464000] Parcel 285 removed from outfeed 0\n",
      "[09:16:46.065000] Parcel 281 removed from outfeed 2\n",
      "[09:16:52.706000] Parcel 288 removed from outfeed 1\n",
      "[09:16:52.964000] Parcel 286 removed from outfeed 0\n",
      "[09:16:53.565000] Parcel 282 removed from outfeed 2\n",
      "[09:16:59.464000] Parcel 287 removed from outfeed 0\n",
      "[09:17:01.065000] Parcel 284 removed from outfeed 2\n",
      "[09:17:06.964000] Parcel 289 removed from outfeed 0\n",
      "[09:17:08.565000] Parcel 290 removed from outfeed 2\n",
      "[09:17:14.464000] Parcel 291 removed from outfeed 0\n",
      "[09:17:15.325000] Parcel 294 removed from outfeed 2\n",
      "[09:17:22.964000] Parcel 293 removed from outfeed 0\n",
      "[09:17:25.107000] Parcel 296 removed from outfeed 2\n",
      "[09:17:29.464000] Parcel 295 removed from outfeed 0\n",
      "[09:17:31.607000] Parcel 297 removed from outfeed 2\n",
      "[09:17:33.202000] Parcel 300 removed from outfeed 1\n",
      "[09:17:36.964000] Parcel 299 removed from outfeed 0\n",
      "[09:17:39.107000] Parcel 298 removed from outfeed 2\n",
      "\n",
      "Total parcels processed: 293\n",
      "Parcels recirculated: 12\n",
      "Success rate (no recirc on first pass): 96.59%\n",
      "Outfeed 0: 106 parcels, 36.18% of sorted\n",
      "Outfeed 1: 48 parcels, 16.38% of sorted\n",
      "Outfeed 2: 139 parcels, 47.44% of sorted\n",
      "Throughput (sorted + recirculated): 305\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# DATA CLEANING FUNCTIONS\n",
    "# --------------------------------------------------------------------------\n",
    "def remove_outliers_iqr(df, cols):\n",
    "    for c in cols:\n",
    "        Q1, Q3 = df[c].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        df = df[df[c].between(Q1 - 2 * IQR, Q3 + 2 * IQR)]\n",
    "    return df\n",
    "\n",
    "def drop_rows_without_true_outfeed(df, prefix=\"Outfeed\"):\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    return df[df[cols].any(axis=1)] if cols else df\n",
    "\n",
    "def clean_parcel_data(df):\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    df = remove_outliers_iqr(df, [\"Length\", \"Width\", \"Height\"])\n",
    "    df = drop_rows_without_true_outfeed(df)\n",
    "    return df\n",
    "\n",
    "def load_parcels_from_clean_df(df):\n",
    "    parcels = []\n",
    "    for _, r in df.iterrows():\n",
    "        parcels.append(Parcel(\n",
    "            pid=int(r[\"Parcel Number\"]),\n",
    "            arrival_time=pd.to_datetime(r[\"Arrival Time\"]),\n",
    "            length=float(r[\"Length\"]),\n",
    "            width=float(r[\"Width\"]),\n",
    "            height=float(r[\"Height\"]),\n",
    "            weight=float(r[\"Weight\"]),\n",
    "            feasible=[i for i, f in enumerate(\n",
    "                [r[\"Outfeed 1\"], r[\"Outfeed 2\"], r[\"Outfeed 3\"]]) if f]\n",
    "        ))\n",
    "    return sorted(parcels, key=lambda p: p.arrival_time)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# EVENT, FES, PARCEL\n",
    "# --------------------------------------------------------------------------\n",
    "class Event:\n",
    "    ARRIVAL = 0\n",
    "    ENTER_SCANNER = 1\n",
    "    ENTER_OUTFEED = 2\n",
    "    EXIT_OUTFEED = 3\n",
    "    RECIRCULATE = 4\n",
    "    def __init__(self, typ, time, parcel, outfeed_id=None): # type is a reserved word\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        param1 (typ): What type of event it is, e.g, Arrival, scanner...\n",
    "        param2 (time): at what time the event occurs.\n",
    "        param3 (parcel): all the information of the parcel that is being processed.\n",
    "        param4 (outfeed_id): the outfeed to which the parcel goes. It is an optional parameter since it is only needed for events 2 and 3.\n",
    "        \"\"\"\n",
    "        self.type = typ\n",
    "        self.time = time  # float: seconds since t0\n",
    "        self.parcel = parcel\n",
    "        self.outfeed_id = outfeed_id # Only used for ENTER_OUTFEED and EXIT_OUTFEED events\n",
    "    def __lt__(self, other):\n",
    "        return self.time < other.time\n",
    "\n",
    "class FES:\n",
    "    \"\"\"\n",
    "    Future Event Set (FES) for discrete event simulation.\n",
    "    This class uses a priority queue to manage events in the simulation.\n",
    "    Events are sorted by their time attribute, which is a float.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.events = []\n",
    "    def add(self, event):\n",
    "        heapq.heappush(self.events, event)\n",
    "    def next(self):\n",
    "        return heapq.heappop(self.events)\n",
    "    def isEmpty(self):\n",
    "        return len(self.events) == 0\n",
    "\n",
    "class Parcel: #This replicates the Customer class, in which info about the customers (parcels) is stored.\n",
    "    def __init__(self, pid, arrival_time, length, width, height, weight, feasible):\n",
    "        self.id = pid\n",
    "        self.arrival_time = arrival_time\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        self.feasible_outfeeds = feasible\n",
    "        self.sorted = False\n",
    "        self.recirculated = False\n",
    "        self.outfeed_attempts = [] #Afterwards, makes a copy of the feasible outfeeds of the parcel. Used for the algorithm functioning.\n",
    "        self.recirculation_count = 0\n",
    "\n",
    "    def get_volume(self):\n",
    "        return self.length * self.width * self.height\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# OUTFEED MODEL\n",
    "# --------------------------------------------------------------------------\n",
    "def compute_outfeed_time(parcel):\n",
    "    base_time = 4.5\n",
    "\n",
    "    # Volume classes\n",
    "    volume = parcel.get_volume()\n",
    "    if volume < 0.035:\n",
    "        volume_class_delay = 0\n",
    "    elif volume < 0.055:\n",
    "        volume_class_delay = 1\n",
    "    else:\n",
    "        volume_class_delay = 2\n",
    "\n",
    "    # Weight classes\n",
    "    weight = parcel.weight\n",
    "    if weight < 1700:\n",
    "        weight_class_delay = 0\n",
    "    elif weight < 2800:\n",
    "        weight_class_delay = 1\n",
    "    else:\n",
    "        weight_class_delay = 2\n",
    "\n",
    "    return base_time + volume_class_delay + weight_class_delay\n",
    "\n",
    "#Probably not to be used in this code, I leave it here now just in case, but the outfeed functioning goes in the simualation class.\n",
    "class Outfeed:\n",
    "    def __init__(self, max_length=3.0):\n",
    "        self.max_length = max_length\n",
    "        self.current_length = 0.0\n",
    "        self.queue = []   # list of (Parcel, service_time)\n",
    "        self.next_time = 0.0\n",
    "    \n",
    "    def can_accept(self, parcel):\n",
    "        return self.current_length + parcel.length <= self.max_length\n",
    "    \n",
    "    def add_parcel(self, parcel):\n",
    "        t = compute_outfeed_time(parcel)\n",
    "        self.queue.append((parcel, t))\n",
    "        self.current_length += parcel.length\n",
    "        if len(self.queue) == 1:\n",
    "            #Timer for the current parcel \n",
    "            self.next_time = t\n",
    "    \n",
    "    def update(self, dt):\n",
    "        self.next_time -= dt\n",
    "        if self.next_time <= 0 and self.queue:\n",
    "            p, _ = self.queue.pop(0)\n",
    "            self.current_length -= p.length\n",
    "            if self.queue:\n",
    "                #Timer for the next parcel in line\n",
    "                self.next_time = self.queue[0][1]\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# POSISORTER with Windowed Local Search + Logging + Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "class PosiSorterSystem:\n",
    "    REBALANCE_INTERVAL = 1      # run hill-climb every N arrivals\n",
    "\n",
    "    def __init__(self, layout_df): #Not sure if i should add arrdist or something similar here.\n",
    "\n",
    "        L = layout_df.set_index(\"Layout property\")[\"Value\"]\n",
    "        self.belt_speed = L[\"Belt Speed\"]\n",
    "        self.d_in_sc = L[\"Distance Infeeds to Scanner\"]\n",
    "        self.d_sc_of = L[\"Distance Scanner to Outfeeds\"]\n",
    "        self.d_between = L[\"Distance between Outfeeds\"]\n",
    "        self.d_of_in = L[\"Distance Outfeeds to Infeeds\"]\n",
    "        self.num_outfeeds = 3 # Given in Excel sheet. Can be automatically detected from the layout_df if needed.\n",
    "        self.outfeeds = [Outfeed(max_length=3.0) for _ in range(self.num_outfeeds)]\n",
    "        #These are used to print statistics about the system:\n",
    "        self.recirculated_count = 0\n",
    "        self.outfeed_counts = [0] * self.num_outfeeds\n",
    "        self.total_processed = 0\n",
    "        self.first_pass_failures = set()\n",
    "        # Greedy + periodic windowed local search\n",
    "        self.loads = {k: 0.0 for k in range(self.num_outfeeds)}   # tracked load per outfeed\n",
    "        self.assignment = {}                                      # parcel.id -> outfeed or None\n",
    "        self.WINDOW_DURATION = self.d_sc_of /self.belt_speed      # Time stamp of window in seconds\n",
    "        self.window = deque()              \n",
    "        self.rebal_ctr = 0\n",
    "    \n",
    "    def greedy(self, p):\n",
    "        # Initial assignment: choose feasible outfeed with minimal tracked load\n",
    "        feas = [k for k in p.feasible_outfeeds if self.loads[k] + p.length <= self.outfeeds[k].max_length]\n",
    "        if not feas:\n",
    "            return None\n",
    "        else:\n",
    "            return min(feas, key=lambda k: self.loads[k])\n",
    "\n",
    "    def imbalance(self, loads):\n",
    "        # Objective: load spread between heaviest and lightest outfeed\n",
    "        return max(loads.values()) - min(loads.values())\n",
    "\n",
    "    def run_local_search(self, max_iters=100):\n",
    "        # Hill-climbing to refine assignments in the sliding window\n",
    "        loads = self.loads.copy()\n",
    "        assign_w = {}\n",
    "        # Baseline: assign any unassigned parcels in window greedily\n",
    "        for _, p in self.window:\n",
    "            k = self.greedy(p)\n",
    "            assign_w[p.id] = k  \n",
    "            if k is not None:\n",
    "                loads[k] += p.length\n",
    "        # Iteratively try moves that reduce imbalance\n",
    "        for _ in range(max_iters):\n",
    "            improved = False\n",
    "            for _, p in self.window:\n",
    "                cur = assign_w[p.id]\n",
    "                for k in p.feasible_outfeeds:\n",
    "                    if k == cur or loads[k] + p.length > self.outfeeds[k].max_length:\n",
    "                        continue\n",
    "                    new_loads = loads.copy()\n",
    "                    if cur is not None:\n",
    "                        new_loads[cur] -= p.length\n",
    "                    new_loads[k] += p.length\n",
    "                    if self.imbalance(new_loads) < self.imbalance(loads):\n",
    "                        loads, assign_w[p.id] = new_loads, k\n",
    "                        improved = True\n",
    "                        break\n",
    "                if improved:\n",
    "                    break\n",
    "            if not improved:\n",
    "                break\n",
    "        # Commit improved assignments\n",
    "        for pid, k in assign_w.items():\n",
    "            self.assignment[pid] = k\n",
    "\n",
    "    def handle_enter_scanner(self, evt, fes):\n",
    "        p = evt.parcel\n",
    "        # 1) greedy assign\n",
    "        k0 = self.greedy(p)\n",
    "        self.assignment[p.id] = k0\n",
    "        # track failure on first pass\n",
    "        if k0 is None:\n",
    "            self.first_pass_failures.add(p.id)\n",
    "        # 2) window and rebalance\n",
    "        self.window.append((evt.time, p))\n",
    "        # Remove parcels outside the window\n",
    "        while self.window and evt.time - self.window[0][0] > self.WINDOW_DURATION:\n",
    "            self.window.popleft()\n",
    "        self.rebal_ctr += 1\n",
    "        if self.rebal_ctr >= self.REBALANCE_INTERVAL:\n",
    "            self.run_local_search()\n",
    "            self.rebal_ctr = 0\n",
    "        # 3) schedule\n",
    "        t = evt.time\n",
    "        if self.assignment[p.id] is None:\n",
    "            # No feasible outfeed: recirculate\n",
    "            self.recirculated_count += 1\n",
    "            dt = (self.d_sc_of + self.d_between * self.num_outfeeds) / self.belt_speed\n",
    "            fes.add(Event(Event.RECIRCULATE, t + dt, p))\n",
    "        else:\n",
    "            # Schedule entering chosen outfeed\n",
    "            k = self.assignment[p.id]\n",
    "            dt = (self.d_sc_of + k * self.d_between) / self.belt_speed\n",
    "            fes.add(Event(Event.ENTER_OUTFEED, t + dt, p, outfeed_id=k))\n",
    "\n",
    "    def simulate(self, parcels):\n",
    "        fes = FES()\n",
    "        t = 0\n",
    "        t0 = parcels[0].arrival_time #We need to convert the arrival time to seconds, since the rest of the times are in seconds.\n",
    "        #With this for loop, we initiate the simulation by adding all the arrival events of the excel file to the FES. It might not be the most efficient way, \n",
    "        # but I think it works since anyways, the events are sorted by time in the FES afterwards.\n",
    "        for p in parcels:\n",
    "            t = (p.arrival_time - t0).total_seconds()\n",
    "            fes.add(Event(Event.ARRIVAL, t, p)) # schedule the event\n",
    "        while not fes.isEmpty(): # T is still to be determined\n",
    "            told = t #not being used right now, ususally used to store waiting times.\n",
    "            evt = fes.next() #retrieve the next event in the FES and removes it\n",
    "            t = evt.time\n",
    "            if evt.type == Event.ARRIVAL:\n",
    "                fes.add(Event(Event.ENTER_SCANNER, evt.time + self.d_in_sc / self.belt_speed, evt.parcel))\n",
    "            ### Handle outfeed events based on the load balacing and local search\n",
    "            elif evt.type == Event.ENTER_SCANNER:\n",
    "                self.handle_enter_scanner(evt, fes)\n",
    "            elif evt.type == Event.ENTER_OUTFEED:\n",
    "                k, p = evt.outfeed_id, evt.parcel\n",
    "                f = self.outfeeds[k]\n",
    "                f.add_parcel(p)\n",
    "                self.outfeed_counts[k] += 1\n",
    "                self.loads[k] += p.length\n",
    "                if len(f.queue) == 1:\n",
    "                    fes.add(Event(\n",
    "                        Event.EXIT_OUTFEED,\n",
    "                        evt.time + f.queue[0][1],\n",
    "                        p, outfeed_id=k\n",
    "                    ))\n",
    "            elif evt.type == Event.EXIT_OUTFEED:\n",
    "                k, p = evt.outfeed_id, evt.parcel\n",
    "                f = self.outfeeds[k]\n",
    "                f.update(f.next_time)\n",
    "                self.loads[k] -= p.length\n",
    "                actual_time = t0 + timedelta(seconds=evt.time)\n",
    "                print(f\"[{actual_time.time()}] Parcel {p.id} removed from outfeed {k}\")\n",
    "                if f.queue:\n",
    "                    fes.add(Event(\n",
    "                        Event.EXIT_OUTFEED,\n",
    "                        evt.time + f.queue[0][1],\n",
    "                        f.queue[0][0], outfeed_id=k\n",
    "                    ))\n",
    "            elif evt.type == Event.RECIRCULATE:\n",
    "                fes.add(Event(\n",
    "                    Event.ENTER_SCANNER,\n",
    "                    evt.time + (self.d_of_in + self.d_in_sc) / self.belt_speed,\n",
    "                    evt.parcel\n",
    "                ))\n",
    "        # final summary\n",
    "        total = len(parcels)\n",
    "        sorted_total = sum(self.outfeed_counts)\n",
    "        success_rate = (total - len(self.first_pass_failures)) / total * 100\n",
    "        print()\n",
    "        print(f\"Total parcels processed: {len(parcels)}\")\n",
    "        print(f\"Parcels recirculated: {self.recirculated_count}\")\n",
    "        print(f\"Success rate (no recirc on first pass): {success_rate:.2f}%\")\n",
    "        for i, cnt in enumerate(self.outfeed_counts):\n",
    "            pct = cnt / sorted_total * 100 if sorted_total > 0 else 0\n",
    "            print(f\"Outfeed {i}: {cnt} parcels, {pct:.2f}% of sorted\")\n",
    "        print(f\"Throughput (sorted + recirculated): {sorted_total + self.recirculated_count}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# MAIN\n",
    "# ----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    xls = pd.ExcelFile(\"PosiSorterData1.xlsx\")\n",
    "    df_p = clean_parcel_data(xls.parse(\"Parcels\"))\n",
    "    df_l = xls.parse(\"Layout\")\n",
    "    parcels = load_parcels_from_clean_df(df_p)\n",
    "    system = PosiSorterSystem(df_l)\n",
    "    system.simulate(parcels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
