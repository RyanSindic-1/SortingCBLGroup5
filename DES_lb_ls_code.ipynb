{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e341f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:00:19.158805] Parcel 1 removed from outfeed 0\n",
      "[09:00:25.563083] Parcel 2 removed from outfeed 0\n",
      "[09:00:26.775311] Parcel 16 removed from outfeed 2\n",
      "[09:00:33.220551] Parcel 3 removed from outfeed 0\n",
      "[09:00:33.835874] Parcel 149 removed from outfeed 2\n",
      "[09:00:38.616962] Parcel 4 removed from outfeed 0\n",
      "[09:00:40.376424] Parcel 133 removed from outfeed 2\n",
      "[09:00:45.145185] Parcel 5 removed from outfeed 0\n",
      "[09:00:50.106407] Parcel 6 removed from outfeed 2\n",
      "[09:00:52.369301] Parcel 7 removed from outfeed 0\n",
      "[09:00:53.994107] Parcel 9 removed from outfeed 1\n",
      "[09:00:59.854460] Parcel 10 removed from outfeed 1\n",
      "[09:01:00.853811] Parcel 8 removed from outfeed 0\n",
      "[09:01:01.277002] Parcel 11 removed from outfeed 2\n",
      "[09:01:06.023768] Parcel 12 removed from outfeed 2\n",
      "[09:01:07.519061] Parcel 14 removed from outfeed 0\n",
      "[09:01:15.127623] Parcel 15 removed from outfeed 0\n",
      "[09:01:21.757003] Parcel 17 removed from outfeed 2\n",
      "[09:01:26.974637] Parcel 18 removed from outfeed 2\n",
      "[09:01:35.285594] Parcel 19 removed from outfeed 2\n",
      "[09:01:41.352331] Parcel 20 removed from outfeed 2\n",
      "[09:01:46.260114] Parcel 25 removed from outfeed 0\n",
      "[09:01:49.178065] Parcel 21 removed from outfeed 2\n",
      "[09:01:52.373364] Parcel 27 removed from outfeed 0\n",
      "[09:01:55.607860] Parcel 29 removed from outfeed 1\n",
      "[09:01:56.243577] Parcel 22 removed from outfeed 2\n",
      "[09:02:00.611383] Parcel 28 removed from outfeed 0\n",
      "[09:02:02.193958] Parcel 23 removed from outfeed 2\n",
      "[09:02:07.142530] Parcel 31 removed from outfeed 0\n",
      "[09:02:10.912916] Parcel 24 removed from outfeed 2\n",
      "[09:02:12.660862] Parcel 33 removed from outfeed 1\n",
      "[09:02:14.583767] Parcel 32 removed from outfeed 0\n",
      "[09:02:19.805300] Parcel 34 removed from outfeed 2\n",
      "[09:02:23.984511] Parcel 38 removed from outfeed 1\n",
      "[09:02:24.896001] Parcel 35 removed from outfeed 2\n",
      "[09:02:30.220961] Parcel 36 removed from outfeed 2\n",
      "[09:02:31.761220] Parcel 42 removed from outfeed 0\n",
      "[09:02:37.586615] Parcel 43 removed from outfeed 0\n",
      "[09:02:38.875799] Parcel 37 removed from outfeed 2\n",
      "[09:02:44.965580] Parcel 46 removed from outfeed 0\n",
      "[09:02:47.176086] Parcel 39 removed from outfeed 2\n",
      "[09:02:50.400164] Parcel 47 removed from outfeed 0\n",
      "[09:02:54.807939] Parcel 40 removed from outfeed 2\n",
      "[09:03:00.218891] Parcel 41 removed from outfeed 2\n",
      "[09:03:01.296594] Parcel 52 removed from outfeed 0\n",
      "[09:03:02.069472] Parcel 51 removed from outfeed 1\n",
      "[09:03:06.080558] Parcel 53 removed from outfeed 0\n",
      "[09:03:07.585207] Parcel 48 removed from outfeed 2\n",
      "[09:03:11.186996] Parcel 55 removed from outfeed 1\n",
      "[09:03:14.997147] Parcel 49 removed from outfeed 2\n",
      "[09:03:20.447869] Parcel 56 removed from outfeed 1\n",
      "[09:03:20.610042] Parcel 50 removed from outfeed 2\n",
      "[09:03:28.647242] Parcel 58 removed from outfeed 0\n",
      "[09:03:28.712773] Parcel 54 removed from outfeed 2\n",
      "[09:03:37.045148] Parcel 44 removed from outfeed 2\n",
      "[09:03:42.525216] Parcel 62 removed from outfeed 1\n",
      "[09:03:44.312255] Parcel 45 removed from outfeed 2\n",
      "[09:03:49.813291] Parcel 64 removed from outfeed 1\n",
      "[09:03:51.107481] Parcel 57 removed from outfeed 2\n",
      "[09:03:58.323132] Parcel 65 removed from outfeed 2\n",
      "[09:04:01.757254] Parcel 67 removed from outfeed 0\n",
      "[09:04:05.698383] Parcel 66 removed from outfeed 2\n",
      "[09:04:11.790252] Parcel 68 removed from outfeed 2\n",
      "[09:04:20.064546] Parcel 59 removed from outfeed 2\n",
      "[09:04:26.600028] Parcel 69 removed from outfeed 2\n",
      "[09:04:33.130450] Parcel 74 removed from outfeed 1\n",
      "[09:04:35.149443] Parcel 70 removed from outfeed 2\n",
      "[09:04:41.123972] Parcel 78 removed from outfeed 0\n",
      "[09:04:42.123327] Parcel 60 removed from outfeed 2\n",
      "[09:04:43.325872] Parcel 77 removed from outfeed 1\n",
      "[09:04:47.844584] Parcel 79 removed from outfeed 0\n",
      "[09:04:48.291678] Parcel 61 removed from outfeed 2\n",
      "[09:04:48.453764] Parcel 80 removed from outfeed 1\n",
      "[09:04:53.383517] Parcel 71 removed from outfeed 2\n",
      "[09:04:55.570603] Parcel 81 removed from outfeed 0\n",
      "[09:05:00.490988] Parcel 84 removed from outfeed 0\n",
      "[09:05:00.708999] Parcel 72 removed from outfeed 2\n",
      "[09:05:04.522630] Parcel 83 removed from outfeed 1\n",
      "[09:05:09.196815] Parcel 63 removed from outfeed 2\n",
      "[09:05:10.365214] Parcel 85 removed from outfeed 0\n",
      "[09:05:16.634955] Parcel 73 removed from outfeed 2\n",
      "[09:05:17.343036] Parcel 86 removed from outfeed 0\n",
      "[09:05:23.484765] Parcel 82 removed from outfeed 2\n",
      "[09:05:31.848664] Parcel 76 removed from outfeed 2\n",
      "[09:05:31.919329] Parcel 90 removed from outfeed 0\n",
      "[09:05:36.474116] Parcel 91 removed from outfeed 1\n",
      "[09:05:40.002637] Parcel 87 removed from outfeed 2\n",
      "[09:05:40.795138] Parcel 93 removed from outfeed 0\n",
      "[09:05:42.704946] Parcel 92 removed from outfeed 1\n",
      "[09:05:46.731616] Parcel 88 removed from outfeed 2\n",
      "[09:05:47.927465] Parcel 94 removed from outfeed 0\n",
      "[09:05:48.210487] Parcel 96 removed from outfeed 1\n",
      "[09:05:53.583634] Parcel 89 removed from outfeed 2\n",
      "[09:05:56.195378] Parcel 97 removed from outfeed 1\n",
      "[09:05:57.092734] Parcel 99 removed from outfeed 0\n",
      "[09:06:00.410504] Parcel 95 removed from outfeed 2\n",
      "[09:06:07.681617] Parcel 98 removed from outfeed 2\n",
      "[09:06:09.198723] Parcel 101 removed from outfeed 0\n",
      "[09:06:14.378795] Parcel 100 removed from outfeed 2\n",
      "[09:06:17.791771] Parcel 102 removed from outfeed 0\n",
      "[09:06:20.720268] Parcel 107 removed from outfeed 1\n",
      "[09:06:23.050236] Parcel 105 removed from outfeed 2\n",
      "[09:06:25.425985] Parcel 104 removed from outfeed 0\n",
      "[09:06:32.223080] Parcel 108 removed from outfeed 1\n",
      "[09:06:32.693223] Parcel 106 removed from outfeed 0\n",
      "[09:06:34.056944] Parcel 109 removed from outfeed 2\n",
      "[09:06:38.249079] Parcel 113 removed from outfeed 0\n",
      "[09:06:40.588827] Parcel 110 removed from outfeed 2\n",
      "[09:06:45.219726] Parcel 111 removed from outfeed 2\n",
      "[09:06:45.940383] Parcel 115 removed from outfeed 0\n",
      "[09:06:49.955804] Parcel 112 removed from outfeed 2\n",
      "[09:06:51.762430] Parcel 117 removed from outfeed 0\n",
      "[09:06:57.807801] Parcel 114 removed from outfeed 2\n",
      "[09:07:05.481105] Parcel 116 removed from outfeed 2\n",
      "[09:07:07.669492] Parcel 120 removed from outfeed 0\n",
      "[09:07:12.262609] Parcel 118 removed from outfeed 2\n",
      "[09:07:15.891202] Parcel 123 removed from outfeed 0\n",
      "[09:07:17.389756] Parcel 119 removed from outfeed 2\n",
      "[09:07:24.945298] Parcel 121 removed from outfeed 2\n",
      "[09:07:25.568886] Parcel 126 removed from outfeed 0\n",
      "[09:07:32.569766] Parcel 122 removed from outfeed 2\n",
      "[09:07:34.026028] Parcel 127 removed from outfeed 0\n",
      "[09:07:38.478547] Parcel 124 removed from outfeed 2\n",
      "[09:07:43.741140] Parcel 131 removed from outfeed 0\n",
      "[09:07:44.233213] Parcel 125 removed from outfeed 2\n",
      "[09:07:50.246367] Parcel 129 removed from outfeed 2\n",
      "[09:07:51.818244] Parcel 132 removed from outfeed 0\n",
      "[09:07:56.481217] Parcel 130 removed from outfeed 2\n",
      "[09:07:57.968615] Parcel 134 removed from outfeed 0\n",
      "[09:08:06.361497] Parcel 135 removed from outfeed 2\n",
      "[09:08:07.489189] Parcel 136 removed from outfeed 1\n",
      "[09:08:11.050638] Parcel 139 removed from outfeed 0\n",
      "[09:08:14.189054] Parcel 137 removed from outfeed 1\n",
      "[09:08:17.315103] Parcel 128 removed from outfeed 2\n",
      "[09:08:17.896270] Parcel 140 removed from outfeed 0\n",
      "[09:08:23.357479] Parcel 138 removed from outfeed 2\n",
      "[09:08:24.145738] Parcel 141 removed from outfeed 1\n",
      "[09:08:24.386143] Parcel 142 removed from outfeed 0\n",
      "[09:08:33.161322] Parcel 143 removed from outfeed 2\n",
      "[09:08:37.505370] Parcel 146 removed from outfeed 0\n",
      "[09:08:40.230015] Parcel 144 removed from outfeed 2\n",
      "[09:08:44.770172] Parcel 147 removed from outfeed 0\n",
      "[09:08:45.424379] Parcel 145 removed from outfeed 2\n",
      "[09:08:51.063690] Parcel 150 removed from outfeed 0\n",
      "[09:08:53.422852] Parcel 148 removed from outfeed 2\n",
      "[09:08:56.480306] Parcel 151 removed from outfeed 0\n",
      "[09:09:02.039501] Parcel 152 removed from outfeed 0\n",
      "[09:09:03.287315] Parcel 153 removed from outfeed 2\n",
      "[09:09:09.995756] Parcel 154 removed from outfeed 2\n",
      "[09:09:10.877191] Parcel 155 removed from outfeed 0\n",
      "[09:09:13.152849] Parcel 156 removed from outfeed 1\n",
      "[09:09:17.350850] Parcel 157 removed from outfeed 0\n",
      "[09:09:25.091322] Parcel 159 removed from outfeed 0\n",
      "[09:09:25.662475] Parcel 158 removed from outfeed 2\n",
      "[09:09:37.287993] Parcel 160 removed from outfeed 0\n",
      "[09:09:46.498353] Parcel 161 removed from outfeed 2\n",
      "[09:09:47.576114] Parcel 162 removed from outfeed 1\n",
      "[09:09:55.286160] Parcel 163 removed from outfeed 2\n",
      "[09:10:01.664534] Parcel 165 removed from outfeed 0\n",
      "[09:10:03.444462] Parcel 164 removed from outfeed 2\n",
      "[09:10:07.116606] Parcel 166 removed from outfeed 0\n",
      "[09:10:12.029156] Parcel 167 removed from outfeed 0\n",
      "[09:10:20.218236] Parcel 170 removed from outfeed 1\n",
      "[09:10:20.237609] Parcel 169 removed from outfeed 0\n",
      "[09:10:20.634689] Parcel 168 removed from outfeed 2\n",
      "[09:10:26.042847] Parcel 174 removed from outfeed 1\n",
      "[09:10:27.083221] Parcel 171 removed from outfeed 0\n",
      "[09:10:28.724727] Parcel 173 removed from outfeed 2\n",
      "[09:10:34.045062] Parcel 172 removed from outfeed 0\n",
      "[09:10:34.695547] Parcel 175 removed from outfeed 2\n",
      "[09:10:39.228020] Parcel 176 removed from outfeed 1\n",
      "[09:10:41.793875] Parcel 177 removed from outfeed 2\n",
      "[09:10:44.919896] Parcel 180 removed from outfeed 0\n",
      "[09:10:49.018655] Parcel 179 removed from outfeed 1\n",
      "[09:10:50.393285] Parcel 178 removed from outfeed 2\n",
      "[09:11:00.221710] Parcel 183 removed from outfeed 0\n",
      "[09:11:00.331138] Parcel 182 removed from outfeed 1\n",
      "[09:11:03.800521] Parcel 181 removed from outfeed 2\n",
      "[09:11:05.119989] Parcel 185 removed from outfeed 0\n",
      "[09:11:06.238616] Parcel 184 removed from outfeed 1\n",
      "[09:11:12.151732] Parcel 186 removed from outfeed 2\n",
      "[09:11:13.167315] Parcel 188 removed from outfeed 0\n",
      "[09:11:16.541076] Parcel 189 removed from outfeed 1\n",
      "[09:11:19.069445] Parcel 187 removed from outfeed 2\n",
      "[09:11:26.612250] Parcel 191 removed from outfeed 0\n",
      "[09:11:27.187501] Parcel 190 removed from outfeed 2\n",
      "[09:11:30.445431] Parcel 192 removed from outfeed 1\n",
      "[09:11:33.686783] Parcel 194 removed from outfeed 0\n",
      "[09:11:35.529523] Parcel 193 removed from outfeed 2\n",
      "[09:11:38.981189] Parcel 197 removed from outfeed 1\n",
      "[09:11:40.979722] Parcel 196 removed from outfeed 0\n",
      "[09:11:43.052233] Parcel 195 removed from outfeed 2\n",
      "[09:11:46.140260] Parcel 200 removed from outfeed 1\n",
      "[09:11:47.270514] Parcel 198 removed from outfeed 0\n",
      "[09:11:48.965072] Parcel 201 removed from outfeed 2\n",
      "[09:11:55.024038] Parcel 202 removed from outfeed 2\n",
      "[09:11:56.055843] Parcel 199 removed from outfeed 0\n",
      "[09:11:59.958874] Parcel 208 removed from outfeed 1\n",
      "[09:12:01.691022] Parcel 203 removed from outfeed 0\n",
      "[09:12:02.008441] Parcel 205 removed from outfeed 2\n",
      "[09:12:06.569440] Parcel 204 removed from outfeed 0\n",
      "[09:12:10.730261] Parcel 210 removed from outfeed 2\n",
      "[09:12:14.310782] Parcel 211 removed from outfeed 1\n",
      "[09:12:15.153858] Parcel 206 removed from outfeed 0\n",
      "[09:12:20.439927] Parcel 209 removed from outfeed 0\n",
      "[09:12:25.319069] Parcel 212 removed from outfeed 0\n",
      "[09:12:26.695264] Parcel 215 removed from outfeed 2\n",
      "[09:12:30.958722] Parcel 213 removed from outfeed 0\n",
      "[09:12:33.641332] Parcel 216 removed from outfeed 2\n",
      "[09:12:39.382220] Parcel 214 removed from outfeed 0\n",
      "[09:12:41.112184] Parcel 217 removed from outfeed 2\n",
      "[09:12:44.995829] Parcel 219 removed from outfeed 1\n",
      "[09:12:45.848024] Parcel 220 removed from outfeed 0\n",
      "[09:12:47.503793] Parcel 218 removed from outfeed 2\n",
      "[09:12:52.780758] Parcel 221 removed from outfeed 0\n",
      "[09:12:56.248066] Parcel 222 removed from outfeed 2\n",
      "[09:13:03.287779] Parcel 223 removed from outfeed 2\n",
      "[09:13:03.638334] Parcel 227 removed from outfeed 1\n",
      "[09:13:08.591410] Parcel 224 removed from outfeed 2\n",
      "[09:13:08.916825] Parcel 228 removed from outfeed 1\n",
      "[09:13:15.093794] Parcel 225 removed from outfeed 2\n",
      "[09:13:20.196117] Parcel 232 removed from outfeed 0\n",
      "[09:13:22.126769] Parcel 226 removed from outfeed 2\n",
      "[09:13:25.993560] Parcel 233 removed from outfeed 0\n",
      "[09:13:28.338004] Parcel 229 removed from outfeed 2\n",
      "[09:13:33.020290] Parcel 230 removed from outfeed 2\n",
      "[09:13:34.422906] Parcel 235 removed from outfeed 0\n",
      "[09:13:41.517939] Parcel 231 removed from outfeed 2\n",
      "[09:13:42.764945] Parcel 237 removed from outfeed 0\n",
      "[09:13:49.991782] Parcel 234 removed from outfeed 2\n",
      "[09:13:54.950728] Parcel 236 removed from outfeed 2\n",
      "[09:13:59.177705] Parcel 238 removed from outfeed 1\n",
      "[09:14:02.560368] Parcel 239 removed from outfeed 2\n",
      "[09:14:13.762051] Parcel 240 removed from outfeed 1\n",
      "[09:14:21.312139] Parcel 241 removed from outfeed 2\n",
      "[09:14:28.051210] Parcel 242 removed from outfeed 2\n",
      "[09:14:28.615258] Parcel 246 removed from outfeed 0\n",
      "[09:14:32.800374] Parcel 243 removed from outfeed 2\n",
      "[09:14:34.661609] Parcel 248 removed from outfeed 0\n",
      "[09:14:38.419406] Parcel 249 removed from outfeed 1\n",
      "[09:14:41.367029] Parcel 244 removed from outfeed 2\n",
      "[09:14:46.104513] Parcel 250 removed from outfeed 1\n",
      "[09:14:48.028480] Parcel 245 removed from outfeed 2\n",
      "[09:14:51.765228] Parcel 252 removed from outfeed 1\n",
      "[09:14:53.818177] Parcel 254 removed from outfeed 0\n",
      "[09:14:54.505538] Parcel 247 removed from outfeed 2\n",
      "[09:14:59.842446] Parcel 251 removed from outfeed 2\n",
      "[09:15:02.064062] Parcel 257 removed from outfeed 0\n",
      "[09:15:06.466336] Parcel 253 removed from outfeed 2\n",
      "[09:15:10.021980] Parcel 258 removed from outfeed 0\n",
      "[09:15:12.931721] Parcel 259 removed from outfeed 1\n",
      "[09:15:13.685226] Parcel 255 removed from outfeed 2\n",
      "[09:15:16.894694] Parcel 261 removed from outfeed 0\n",
      "[09:15:20.262287] Parcel 256 removed from outfeed 2\n",
      "[09:15:22.433525] Parcel 262 removed from outfeed 0\n",
      "[09:15:26.077229] Parcel 260 removed from outfeed 2\n",
      "[09:15:31.564137] Parcel 263 removed from outfeed 2\n",
      "[09:15:33.567634] Parcel 266 removed from outfeed 0\n",
      "[09:15:37.721260] Parcel 264 removed from outfeed 2\n",
      "[09:15:40.122422] Parcel 267 removed from outfeed 0\n",
      "[09:15:44.313135] Parcel 265 removed from outfeed 2\n",
      "[09:15:44.835535] Parcel 268 removed from outfeed 1\n",
      "[09:15:49.988472] Parcel 270 removed from outfeed 0\n",
      "[09:15:53.802519] Parcel 269 removed from outfeed 2\n",
      "[09:15:59.849006] Parcel 271 removed from outfeed 2\n",
      "[09:16:12.339548] Parcel 272 removed from outfeed 2\n",
      "[09:16:15.236130] Parcel 274 removed from outfeed 1\n",
      "[09:16:19.371980] Parcel 273 removed from outfeed 2\n",
      "[09:16:23.706102] Parcel 277 removed from outfeed 0\n",
      "[09:16:25.067378] Parcel 275 removed from outfeed 2\n",
      "[09:16:29.817877] Parcel 278 removed from outfeed 0\n",
      "[09:16:31.092524] Parcel 276 removed from outfeed 2\n",
      "[09:16:38.780763] Parcel 283 removed from outfeed 0\n",
      "[09:16:38.808532] Parcel 280 removed from outfeed 1\n",
      "[09:16:38.855821] Parcel 279 removed from outfeed 2\n",
      "[09:16:44.138005] Parcel 285 removed from outfeed 0\n",
      "[09:16:46.588555] Parcel 281 removed from outfeed 2\n",
      "[09:16:46.605050] Parcel 284 removed from outfeed 1\n",
      "[09:16:52.904139] Parcel 286 removed from outfeed 0\n",
      "[09:16:53.232451] Parcel 288 removed from outfeed 1\n",
      "[09:16:53.377777] Parcel 282 removed from outfeed 2\n",
      "[09:16:59.668252] Parcel 287 removed from outfeed 0\n",
      "[09:17:01.910513] Parcel 290 removed from outfeed 2\n",
      "[09:17:06.592480] Parcel 289 removed from outfeed 0\n",
      "[09:17:09.609737] Parcel 291 removed from outfeed 2\n",
      "[09:17:14.538463] Parcel 293 removed from outfeed 0\n",
      "[09:17:16.257307] Parcel 294 removed from outfeed 2\n",
      "[09:17:20.441057] Parcel 295 removed from outfeed 0\n",
      "[09:17:25.676052] Parcel 296 removed from outfeed 2\n",
      "[09:17:28.121543] Parcel 299 removed from outfeed 0\n",
      "[09:17:32.438467] Parcel 297 removed from outfeed 2\n",
      "[09:17:33.266955] Parcel 300 removed from outfeed 1\n",
      "[09:17:40.068990] Parcel 298 removed from outfeed 2\n",
      "\n",
      "Total parcels processed: 293\n",
      "Parcels recirculated: 8\n",
      "Success rate (no recirc on first pass): 97.27%\n",
      "Outfeed 0: 106 parcels, 36.18% of sorted\n",
      "Outfeed 1: 52 parcels, 17.75% of sorted\n",
      "Outfeed 2: 135 parcels, 46.08% of sorted\n",
      "Throughput (sorted + recirculated): 301\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# DATA CLEANING FUNCTIONS\n",
    "# --------------------------------------------------------------------------\n",
    "def remove_outliers_iqr(df, cols):\n",
    "    for c in cols:\n",
    "        Q1, Q3 = df[c].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        df = df[df[c].between(Q1 - 2 * IQR, Q3 + 2 * IQR)]\n",
    "    return df\n",
    "\n",
    "def drop_rows_without_true_outfeed(df, prefix=\"Outfeed\"):\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    return df[df[cols].any(axis=1)] if cols else df\n",
    "\n",
    "def clean_parcel_data(df):\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    df = remove_outliers_iqr(df, [\"Length\", \"Width\", \"Height\"])\n",
    "    df = drop_rows_without_true_outfeed(df)\n",
    "    return df\n",
    "\n",
    "def load_parcels_from_clean_df(df):\n",
    "    parcels = []\n",
    "    for _, r in df.iterrows():\n",
    "        parcels.append(Parcel(\n",
    "            pid=int(r[\"Parcel Number\"]),\n",
    "            arrival_time=pd.to_datetime(r[\"Arrival Time\"]),\n",
    "            length=float(r[\"Length\"]),\n",
    "            width=float(r[\"Width\"]),\n",
    "            height=float(r[\"Height\"]),\n",
    "            weight=float(r[\"Weight\"]),\n",
    "            feasible=[i for i, f in enumerate(\n",
    "                [r[\"Outfeed 1\"], r[\"Outfeed 2\"], r[\"Outfeed 3\"]]) if f]\n",
    "        ))\n",
    "    return sorted(parcels, key=lambda p: p.arrival_time)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# EVENT, FES, PARCEL\n",
    "# --------------------------------------------------------------------------\n",
    "class Event:\n",
    "    ARRIVAL = 0\n",
    "    ENTER_SCANNER = 1\n",
    "    ENTER_OUTFEED = 2\n",
    "    EXIT_OUTFEED = 3\n",
    "    RECIRCULATE = 4\n",
    "    def __init__(self, typ, time, parcel, outfeed_id=None): # type is a reserved word\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        param1 (typ): What type of event it is, e.g, Arrival, scanner...\n",
    "        param2 (time): at what time the event occurs.\n",
    "        param3 (parcel): all the information of the parcel that is being processed.\n",
    "        param4 (outfeed_id): the outfeed to which the parcel goes. It is an optional parameter since it is only needed for events 2 and 3.\n",
    "        \"\"\"\n",
    "        self.type = typ\n",
    "        self.time = time  # float: seconds since t0\n",
    "        self.parcel = parcel\n",
    "        self.outfeed_id = outfeed_id # Only used for ENTER_OUTFEED and EXIT_OUTFEED events\n",
    "    def __lt__(self, other):\n",
    "        return self.time < other.time\n",
    "\n",
    "class FES:\n",
    "    \"\"\"\n",
    "    Future Event Set (FES) for discrete event simulation.\n",
    "    This class uses a priority queue to manage events in the simulation.\n",
    "    Events are sorted by their time attribute, which is a float.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.events = []\n",
    "    def add(self, event):\n",
    "        heapq.heappush(self.events, event)\n",
    "    def next(self):\n",
    "        return heapq.heappop(self.events)\n",
    "    def isEmpty(self):\n",
    "        return len(self.events) == 0\n",
    "\n",
    "class Parcel: #This replicates the Customer class, in which info about the customers (parcels) is stored.\n",
    "    def __init__(self, pid, arrival_time, length, width, height, weight, feasible):\n",
    "        self.id = pid\n",
    "        self.arrival_time = arrival_time\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        self.feasible_outfeeds = feasible\n",
    "        self.sorted = False\n",
    "        self.recirculated = False\n",
    "        self.outfeed_attempts = [] #Afterwards, makes a copy of the feasible outfeeds of the parcel. Used for the algorithm functioning.\n",
    "        self.recirculation_count = 0\n",
    "\n",
    "    def get_volume(self):\n",
    "        return self.length * self.width * self.height\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# OUTFEED MODEL\n",
    "# --------------------------------------------------------------------------\n",
    "def compute_outfeed_time(parcel):\n",
    "    base_time = 4.5\n",
    "\n",
    "    # Volume classes\n",
    "    volume = parcel.get_volume()\n",
    "    if volume < 0.035:\n",
    "        volume_class_delay = random.uniform(0.0, 0.5)\n",
    "    elif volume < 0.055:\n",
    "        volume_class_delay = random.uniform(0.5, 1.5)\n",
    "    else:\n",
    "        volume_class_delay = random.uniform(1.5, 2.5)\n",
    "\n",
    "    # Weight classes\n",
    "    weight = parcel.weight\n",
    "    if weight < 1700:\n",
    "        weight_class_delay = random.uniform(0.0, 0.5)\n",
    "    elif weight < 2800:\n",
    "        weight_class_delay = random.uniform(0.5, 1.5)\n",
    "    else:\n",
    "        weight_class_delay = random.uniform(1.5, 2.5)\n",
    "\n",
    "    return base_time + volume_class_delay + weight_class_delay\n",
    "\n",
    "#Probably not to be used in this code, I leave it here now just in case, but the outfeed functioning goes in the simualation class.\n",
    "class Outfeed:\n",
    "    def __init__(self, max_length=3.0):\n",
    "        self.max_length = max_length\n",
    "        self.current_length = 0.0\n",
    "        self.queue = []   # list of (Parcel, service_time)\n",
    "        self.next_time = 0.0\n",
    "    \n",
    "    def can_accept(self, parcel):\n",
    "        return self.current_length + parcel.length <= self.max_length\n",
    "    \n",
    "    def add_parcel(self, parcel):\n",
    "        t = compute_outfeed_time(parcel)\n",
    "        self.queue.append((parcel, t))\n",
    "        self.current_length += parcel.length\n",
    "        if len(self.queue) == 1:\n",
    "            #Timer for the current parcel \n",
    "            self.next_time = t\n",
    "    \n",
    "    def update(self, dt):\n",
    "        self.next_time -= dt\n",
    "        if self.next_time <= 0 and self.queue:\n",
    "            p, _ = self.queue.pop(0)\n",
    "            self.current_length -= p.length\n",
    "            if self.queue:\n",
    "                #Timer for the next parcel in line\n",
    "                self.next_time = self.queue[0][1]\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# POSISORTER with Windowed Local Search + Logging + Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "class PosiSorterSystem:\n",
    "    WINDOW_SIZE = 10           # size of sliding-window for local search\n",
    "    REBALANCE_INTERVAL = 1      # run hill-climb every N arrivals\n",
    "\n",
    "    def __init__(self, layout_df): #Not sure if i should add arrdist or something similar here.\n",
    "        L = layout_df.set_index(\"Layout property\")[\"Value\"]\n",
    "        self.belt_speed = L[\"Belt Speed\"]\n",
    "        self.d_in_sc = L[\"Distance Infeeds to Scanner\"]\n",
    "        self.d_sc_of = L[\"Distance Scanner to Outfeeds\"]\n",
    "        self.d_between = L[\"Distance between Outfeeds\"]\n",
    "        self.d_of_in = L[\"Distance Outfeeds to Infeeds\"]\n",
    "        self.num_outfeeds = 3 # Given in Excel sheet. Can be automatically detected from the layout_df if needed.\n",
    "        self.outfeeds = [Outfeed(max_length=3.0) for _ in range(self.num_outfeeds)]\n",
    "        #These are used to print statistics about the system:\n",
    "        self.recirculated_count = 0\n",
    "        self.outfeed_counts = [0] * self.num_outfeeds\n",
    "        self.total_processed = 0\n",
    "        self.first_pass_failures = set()\n",
    "        # Greedy + periodic windowed local search\n",
    "        self.loads = {k: 0.0 for k in range(self.num_outfeeds)}   # tracked load per outfeed\n",
    "        self.assignment = {}                                      # parcel.id -> outfeed or None\n",
    "        self.window = deque(maxlen=self.WINDOW_SIZE)              # recent scanned parcels\n",
    "        self.rebal_ctr = 0\n",
    "    \n",
    "    def greedy(self, p):\n",
    "        # Initial assignment: choose feasible outfeed with minimal tracked load\n",
    "        feas = [k for k in p.feasible_outfeeds if self.loads[k] + p.length <= self.outfeeds[k].max_length]\n",
    "        if not feas:\n",
    "            return None\n",
    "        else:\n",
    "            return min(feas, key=lambda k: self.loads[k])\n",
    "\n",
    "    def imbalance(self, loads):\n",
    "        # Objective: load spread between heaviest and lightest outfeed\n",
    "        return max(loads.values()) - min(loads.values())\n",
    "\n",
    "    def run_local_search(self, max_iters=100):\n",
    "        # Hill-climbing to refine assignments in the sliding window\n",
    "        loads = self.loads.copy()\n",
    "        assign_w = {}\n",
    "        # Baseline: assign any unassigned parcels in window greedily\n",
    "        for p in self.window:\n",
    "            k = self.greedy(p)\n",
    "            assign_w[p.id] = k\n",
    "            if k is not None:\n",
    "                loads[k] += p.length\n",
    "        # Iteratively try moves that reduce imbalance\n",
    "        for _ in range(max_iters):\n",
    "            improved = False\n",
    "            for p in self.window:\n",
    "                cur = assign_w[p.id]\n",
    "                for k in p.feasible_outfeeds:\n",
    "                    if k == cur or loads[k] + p.length > self.outfeeds[k].max_length:\n",
    "                        continue\n",
    "                    new_loads = loads.copy()\n",
    "                    if cur is not None:\n",
    "                        new_loads[cur] -= p.length\n",
    "                    new_loads[k] += p.length\n",
    "                    if self.imbalance(new_loads) < self.imbalance(loads):\n",
    "                        loads, assign_w[p.id] = new_loads, k\n",
    "                        improved = True\n",
    "                        break\n",
    "                if improved:\n",
    "                    break\n",
    "            if not improved:\n",
    "                break\n",
    "        # Commit improved assignments\n",
    "        for pid, k in assign_w.items():\n",
    "            self.assignment[pid] = k\n",
    "\n",
    "    def handle_enter_scanner(self, evt, fes):\n",
    "        p = evt.parcel\n",
    "        # 1) greedy assign\n",
    "        k0 = self.greedy(p)\n",
    "        self.assignment[p.id] = k0\n",
    "        # track failure on first pass\n",
    "        if k0 is None:\n",
    "            self.first_pass_failures.add(p.id)\n",
    "        # 2) window and rebalance\n",
    "        self.window.append(p)\n",
    "        self.rebal_ctr += 1\n",
    "        if self.rebal_ctr >= self.REBALANCE_INTERVAL:\n",
    "            self.run_local_search()\n",
    "            self.rebal_ctr = 0\n",
    "        # 3) schedule\n",
    "        t = evt.time\n",
    "        if self.assignment[p.id] is None:\n",
    "            # No feasible outfeed: recirculate\n",
    "            self.recirculated_count += 1\n",
    "            dt = (self.d_sc_of + self.d_between * self.num_outfeeds) / self.belt_speed\n",
    "            fes.add(Event(Event.RECIRCULATE, t + dt, p))\n",
    "        else:\n",
    "            # Schedule entering chosen outfeed\n",
    "            k = self.assignment[p.id]\n",
    "            dt = (self.d_sc_of + k * self.d_between) / self.belt_speed\n",
    "            fes.add(Event(Event.ENTER_OUTFEED, t + dt, p, outfeed_id=k))\n",
    "\n",
    "    def simulate(self, parcels):\n",
    "        fes = FES()\n",
    "        t = 0\n",
    "        t0 = parcels[0].arrival_time #We need to convert the arrival time to seconds, since the rest of the times are in seconds.\n",
    "        #With this for loop, we initiate the simulation by adding all the arrival events of the excel file to the FES. It might not be the most efficient way, \n",
    "        # but I think it works since anyways, the events are sorted by time in the FES afterwards.\n",
    "        for p in parcels:\n",
    "            t = (p.arrival_time - t0).total_seconds()\n",
    "            fes.add(Event(Event.ARRIVAL, t, p)) # schedule the event\n",
    "        while not fes.isEmpty(): # T is still to be determined\n",
    "            told = t #not being used right now, ususally used to store waiting times.\n",
    "            evt = fes.next() #retrieve the next event in the FES and removes it\n",
    "            t = evt.time\n",
    "            if evt.type == Event.ARRIVAL:\n",
    "                fes.add(Event(Event.ENTER_SCANNER, evt.time + self.d_in_sc / self.belt_speed, evt.parcel))\n",
    "            ### Handle outfeed events based on the load balacing and local search\n",
    "            elif evt.type == Event.ENTER_SCANNER:\n",
    "                self.handle_enter_scanner(evt, fes)\n",
    "            elif evt.type == Event.ENTER_OUTFEED:\n",
    "                k, p = evt.outfeed_id, evt.parcel\n",
    "                f = self.outfeeds[k]\n",
    "                f.add_parcel(p)\n",
    "                self.outfeed_counts[k] += 1\n",
    "                self.loads[k] += p.length\n",
    "                if len(f.queue) == 1:\n",
    "                    fes.add(Event(\n",
    "                        Event.EXIT_OUTFEED,\n",
    "                        evt.time + f.queue[0][1],\n",
    "                        p, outfeed_id=k\n",
    "                    ))\n",
    "            elif evt.type == Event.EXIT_OUTFEED:\n",
    "                k, p = evt.outfeed_id, evt.parcel\n",
    "                f = self.outfeeds[k]\n",
    "                f.update(f.next_time)\n",
    "                self.loads[k] -= p.length\n",
    "                actual_time = t0 + timedelta(seconds=evt.time)\n",
    "                print(f\"[{actual_time.time()}] Parcel {p.id} removed from outfeed {k}\")\n",
    "                if f.queue:\n",
    "                    fes.add(Event(\n",
    "                        Event.EXIT_OUTFEED,\n",
    "                        evt.time + f.queue[0][1],\n",
    "                        f.queue[0][0], outfeed_id=k\n",
    "                    ))\n",
    "            elif evt.type == Event.RECIRCULATE:\n",
    "                fes.add(Event(\n",
    "                    Event.ENTER_SCANNER,\n",
    "                    evt.time + (self.d_of_in + self.d_in_sc) / self.belt_speed,\n",
    "                    evt.parcel\n",
    "                ))\n",
    "        # final summary\n",
    "        total = len(parcels)\n",
    "        sorted_total = sum(self.outfeed_counts)\n",
    "        success_rate = (total - len(self.first_pass_failures)) / total * 100\n",
    "        print()\n",
    "        print(f\"Total parcels processed: {len(parcels)}\")\n",
    "        print(f\"Parcels recirculated: {self.recirculated_count}\")\n",
    "        print(f\"Success rate (no recirc on first pass): {success_rate:.2f}%\")\n",
    "        for i, cnt in enumerate(self.outfeed_counts):\n",
    "            pct = cnt / sorted_total * 100 if sorted_total > 0 else 0\n",
    "            print(f\"Outfeed {i}: {cnt} parcels, {pct:.2f}% of sorted\")\n",
    "        print(f\"Throughput (sorted + recirculated): {sorted_total + self.recirculated_count}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# MAIN\n",
    "# ----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    xls = pd.ExcelFile(\"PosiSorterData1.xlsx\")\n",
    "    df_p = clean_parcel_data(xls.parse(\"Parcels\"))\n",
    "    df_l = xls.parse(\"Layout\")\n",
    "    parcels = load_parcels_from_clean_df(df_p)\n",
    "    system = PosiSorterSystem(df_l)\n",
    "    system.simulate(parcels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
